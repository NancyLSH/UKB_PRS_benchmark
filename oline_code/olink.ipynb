{"metadata": {"language_info": {"name": "python", "version": "3.11.5", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "kernelspec": {"name": "python3", "display_name": "Python 3 (ipykernel)", "language": "python"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "# Import packages\n# dxpy allows python to interact with the platform storage\n# Note: This notebook is using spark since the size of the dataset we're extracting\n# (i.e. the number of fields) is too large for a single node instance.\nimport dxpy\nimport pandas as pd\nimport subprocess\nimport glob\nimport os\nimport pyspark\nfrom pyspark import SparkConf, SparkContext\nfrom pyspark.sql import SQLContext", "metadata": {"trusted": true, "tags": []}, "execution_count": 1, "outputs": []}, {"cell_type": "code", "source": "output_dir = \"/output/\"", "metadata": {"trusted": true, "tags": []}, "execution_count": 2, "outputs": []}, {"cell_type": "code", "source": "# Automatically discover dispensed dataset ID\ndispensed_dataset = dxpy.find_one_data_object(\n    typename=\"Dataset\", name=\"app*.dataset\", folder=\"/\", name_mode=\"glob\"\n)\ndispensed_dataset_id = dispensed_dataset[\"id\"]", "metadata": {"trusted": true, "tags": []}, "execution_count": 3, "outputs": []}, {"cell_type": "code", "source": "# Get project ID\nproject_id = dxpy.find_one_project()[\"id\"]", "metadata": {"trusted": true, "tags": []}, "execution_count": 4, "outputs": []}, {"cell_type": "code", "source": "dataset = (\":\").join([project_id, dispensed_dataset_id])", "metadata": {"trusted": true, "tags": []}, "execution_count": 5, "outputs": []}, {"cell_type": "code", "source": "# Note: This cell can only be run once. Otherwise, you'll need to delete the existing data tables in order to re-run\ncmd = [\"dx\", \"extract_dataset\", dataset, \"-ddd\", \"--delimiter\", \",\"]\nsubprocess.check_call(cmd)", "metadata": {"trusted": true, "tags": []}, "execution_count": 6, "outputs": [{"execution_count": 6, "output_type": "execute_result", "data": {"text/plain": "0"}, "metadata": {}}]}, {"cell_type": "code", "source": "path = os.getcwd()", "metadata": {"trusted": true, "tags": []}, "execution_count": 7, "outputs": []}, {"cell_type": "code", "source": "data_dict_csv = glob.glob(os.path.join(path, \"*.data_dictionary.csv\"))[0]\ndata_dict_df = pd.read_csv(data_dict_csv)\ndata_dict_df.head()", "metadata": {"trusted": true, "tags": []}, "execution_count": 9, "outputs": [{"name": "stderr", "text": "/tmp/ipykernel_119/118131557.py:2: DtypeWarning: Columns (4,7,8,9,10,15) have mixed types. Specify dtype option on import or set low_memory=False.\n  data_dict_df = pd.read_csv(data_dict_csv)\n", "output_type": "stream"}, {"execution_count": 9, "output_type": "execute_result", "data": {"text/plain": "        entity   name     type primary_key_type coding_name  concept  \\\n0  participant    eid   string           global         NaN      NaN   \n1  participant  p3_i0  integer              NaN         NaN      NaN   \n2  participant  p3_i1  integer              NaN         NaN      NaN   \n3  participant  p3_i2  integer              NaN         NaN      NaN   \n4  participant  p3_i3  integer              NaN         NaN      NaN   \n\n   description                                        folder_path  \\\n0          NaN                            Participant Information   \n1          NaN  Assessment centre > Procedural metrics > Proce...   \n2          NaN  Assessment centre > Procedural metrics > Proce...   \n3          NaN  Assessment centre > Procedural metrics > Proce...   \n4          NaN  Assessment centre > Procedural metrics > Proce...   \n\n  is_multi_select is_sparse_coding  \\\n0             NaN              NaN   \n1             NaN              NaN   \n2             NaN              NaN   \n3             NaN              NaN   \n4             NaN              NaN   \n\n                                             linkout  longitudinal_axis_type  \\\n0                                                NaN                     NaN   \n1  http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...                     NaN   \n2  http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...                     NaN   \n3  http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...                     NaN   \n4  http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...                     NaN   \n\n  referenced_entity_field relationship  \\\n0                     NaN          NaN   \n1                     NaN          NaN   \n2                     NaN          NaN   \n3                     NaN          NaN   \n4                     NaN          NaN   \n\n                                    title    units  \n0                          Participant ID      NaN  \n1  Verbal interview duration | Instance 0  seconds  \n2  Verbal interview duration | Instance 1  seconds  \n3  Verbal interview duration | Instance 2  seconds  \n4  Verbal interview duration | Instance 3  seconds  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>entity</th>\n      <th>name</th>\n      <th>type</th>\n      <th>primary_key_type</th>\n      <th>coding_name</th>\n      <th>concept</th>\n      <th>description</th>\n      <th>folder_path</th>\n      <th>is_multi_select</th>\n      <th>is_sparse_coding</th>\n      <th>linkout</th>\n      <th>longitudinal_axis_type</th>\n      <th>referenced_entity_field</th>\n      <th>relationship</th>\n      <th>title</th>\n      <th>units</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>participant</td>\n      <td>eid</td>\n      <td>string</td>\n      <td>global</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Participant Information</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Participant ID</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>participant</td>\n      <td>p3_i0</td>\n      <td>integer</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Assessment centre &gt; Procedural metrics &gt; Proce...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Verbal interview duration | Instance 0</td>\n      <td>seconds</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>participant</td>\n      <td>p3_i1</td>\n      <td>integer</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Assessment centre &gt; Procedural metrics &gt; Proce...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Verbal interview duration | Instance 1</td>\n      <td>seconds</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>participant</td>\n      <td>p3_i2</td>\n      <td>integer</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Assessment centre &gt; Procedural metrics &gt; Proce...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Verbal interview duration | Instance 2</td>\n      <td>seconds</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>participant</td>\n      <td>p3_i3</td>\n      <td>integer</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Assessment centre &gt; Procedural metrics &gt; Proce...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Verbal interview duration | Instance 3</td>\n      <td>seconds</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"cell_type": "code", "source": "print(data_dict_df[\"entity\"].unique())", "metadata": {"trusted": true, "tags": []}, "execution_count": 22, "outputs": [{"name": "stdout", "text": "['participant' 'covid19_result_england' 'covid19_result_scotland'\n 'covid19_result_wales' 'gp_clinical' 'gp_scripts' 'gp_registrations'\n 'hesin' 'hesin_diag' 'hesin_oper' 'hesin_critical' 'hesin_maternity'\n 'hesin_delivery' 'hesin_psych' 'death' 'death_cause' 'olink_instance_0'\n 'olink_instance_2' 'olink_instance_3']\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "field_names = list(\n    data_dict_df.loc[data_dict_df[\"entity\"] == \"olink_instance_0\", \"name\"].values\n)\nprint(len(field_names))", "metadata": {"trusted": true, "tags": []}, "execution_count": 10, "outputs": [{"name": "stdout", "text": "2924\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "field_names_str = [f\"olink_instance_0.{f}\" for f in field_names]\nfield_names_query = \",\".join(field_names_str)", "metadata": {"trusted": true, "tags": []}, "execution_count": 11, "outputs": []}, {"cell_type": "code", "source": "conf = pyspark.SparkConf().set(\"spark.kryoserializer.buffer.max\", \"128m\")", "metadata": {"trusted": true, "tags": []}, "execution_count": 12, "outputs": []}, {"cell_type": "code", "source": "sc = pyspark.SparkContext(conf=conf)\nspark = pyspark.sql.SparkSession(sc)\nsqlContext = SQLContext(sc)", "metadata": {"trusted": true, "tags": []}, "execution_count": 13, "outputs": [{"name": "stderr", "text": "/cluster/spark/python/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  warnings.warn(\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "cmd = [\n    \"dx\",\n    \"extract_dataset\",\n    dataset,\n    \"--fields\",\n    field_names_query,\n    \"--delimiter\",\n    \",\",\n    \"--output\",\n    \"extracted_data.sql\",\n    \"--sql\",\n]\nsubprocess.check_call(cmd)", "metadata": {"trusted": true, "tags": []}, "execution_count": 14, "outputs": [{"execution_count": 14, "output_type": "execute_result", "data": {"text/plain": "0"}, "metadata": {}}]}, {"cell_type": "code", "source": "with open(\"extracted_data.sql\", \"r\") as file:\n    retrieve_sql = \"\"\n    for line in file:\n        retrieve_sql += line.strip()", "metadata": {"trusted": true, "tags": []}, "execution_count": 15, "outputs": []}, {"cell_type": "code", "source": "temp_df = spark.sql(retrieve_sql.strip(\";\"))", "metadata": {"trusted": true, "tags": []}, "execution_count": 16, "outputs": []}, {"cell_type": "code", "source": "pdf = temp_df.toPandas()", "metadata": {"trusted": true, "tags": []}, "execution_count": 17, "outputs": []}, {"cell_type": "code", "source": "print(pdf.shape)\npdf.head()", "metadata": {"trusted": true, "tags": []}, "execution_count": 18, "outputs": [{"name": "stdout", "text": "(53013, 2924)\n", "output_type": "stream"}, {"execution_count": 18, "output_type": "execute_result", "data": {"text/plain": "  olink_instance_0.eid  olink_instance_0.a1bg  olink_instance_0.aamdc  \\\n0              1001090                 0.1754                 0.70995   \n1              1001623                 0.1047                -0.57265   \n2              1001945                 0.0171                -0.42595   \n3              1002425                 0.4068                 0.47565   \n4              1003685                    NaN                     NaN   \n\n   olink_instance_0.aarsd1  olink_instance_0.abca2  olink_instance_0.abhd14b  \\\n0                  0.47690                 0.13945                   0.72730   \n1                 -0.98630                 0.27650                   0.47930   \n2                  0.08305                 0.53980                  -0.18125   \n3                  0.17350                     NaN                       NaN   \n4                 -0.50025                     NaN                   0.50085   \n\n   olink_instance_0.abl1  olink_instance_0.abo  olink_instance_0.abraxas2  \\\n0                1.12880               -1.7391                     1.3161   \n1               -0.58300                   NaN                    -1.6316   \n2                0.04590                2.5828                     0.6365   \n3                0.73650               -3.2560                        NaN   \n4                0.26245                   NaN                        NaN   \n\n   olink_instance_0.acaa1  ...  olink_instance_0.zfyve19  \\\n0                 1.88660  ...                    2.0467   \n1                -0.66700  ...                   -0.8054   \n2                -0.28125  ...                    0.6277   \n3                 0.25040  ...                    0.9128   \n4                     NaN  ...                       NaN   \n\n   olink_instance_0.zhx2  olink_instance_0.znf174  olink_instance_0.znf75d  \\\n0                 0.2292                  -0.1017                  -0.3249   \n1                -0.1983                   0.0506                  -0.3820   \n2                 0.1305                  -0.2988                   0.1070   \n3                 0.2516                   0.0125                  -0.0017   \n4                    NaN                      NaN                      NaN   \n\n   olink_instance_0.znf830  olink_instance_0.znrd2  olink_instance_0.znrf4  \\\n0                  0.02490                -0.13155                  0.6771   \n1                  0.09225                -0.70450                 -0.2588   \n2                  3.49710                 0.93995                  1.2968   \n3                 -0.05405                 0.22090                  0.1690   \n4                      NaN                     NaN                     NaN   \n\n   olink_instance_0.zp3  olink_instance_0.zp4  olink_instance_0.zpr1  \n0                2.1311                0.0679                 0.4858  \n1                0.8063               -0.5414                 0.0976  \n2                1.5437                   NaN                -0.0552  \n3               -4.1724               -0.1351                -1.3381  \n4                   NaN                   NaN                    NaN  \n\n[5 rows x 2924 columns]", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>olink_instance_0.eid</th>\n      <th>olink_instance_0.a1bg</th>\n      <th>olink_instance_0.aamdc</th>\n      <th>olink_instance_0.aarsd1</th>\n      <th>olink_instance_0.abca2</th>\n      <th>olink_instance_0.abhd14b</th>\n      <th>olink_instance_0.abl1</th>\n      <th>olink_instance_0.abo</th>\n      <th>olink_instance_0.abraxas2</th>\n      <th>olink_instance_0.acaa1</th>\n      <th>...</th>\n      <th>olink_instance_0.zfyve19</th>\n      <th>olink_instance_0.zhx2</th>\n      <th>olink_instance_0.znf174</th>\n      <th>olink_instance_0.znf75d</th>\n      <th>olink_instance_0.znf830</th>\n      <th>olink_instance_0.znrd2</th>\n      <th>olink_instance_0.znrf4</th>\n      <th>olink_instance_0.zp3</th>\n      <th>olink_instance_0.zp4</th>\n      <th>olink_instance_0.zpr1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1001090</td>\n      <td>0.1754</td>\n      <td>0.70995</td>\n      <td>0.47690</td>\n      <td>0.13945</td>\n      <td>0.72730</td>\n      <td>1.12880</td>\n      <td>-1.7391</td>\n      <td>1.3161</td>\n      <td>1.88660</td>\n      <td>...</td>\n      <td>2.0467</td>\n      <td>0.2292</td>\n      <td>-0.1017</td>\n      <td>-0.3249</td>\n      <td>0.02490</td>\n      <td>-0.13155</td>\n      <td>0.6771</td>\n      <td>2.1311</td>\n      <td>0.0679</td>\n      <td>0.4858</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1001623</td>\n      <td>0.1047</td>\n      <td>-0.57265</td>\n      <td>-0.98630</td>\n      <td>0.27650</td>\n      <td>0.47930</td>\n      <td>-0.58300</td>\n      <td>NaN</td>\n      <td>-1.6316</td>\n      <td>-0.66700</td>\n      <td>...</td>\n      <td>-0.8054</td>\n      <td>-0.1983</td>\n      <td>0.0506</td>\n      <td>-0.3820</td>\n      <td>0.09225</td>\n      <td>-0.70450</td>\n      <td>-0.2588</td>\n      <td>0.8063</td>\n      <td>-0.5414</td>\n      <td>0.0976</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1001945</td>\n      <td>0.0171</td>\n      <td>-0.42595</td>\n      <td>0.08305</td>\n      <td>0.53980</td>\n      <td>-0.18125</td>\n      <td>0.04590</td>\n      <td>2.5828</td>\n      <td>0.6365</td>\n      <td>-0.28125</td>\n      <td>...</td>\n      <td>0.6277</td>\n      <td>0.1305</td>\n      <td>-0.2988</td>\n      <td>0.1070</td>\n      <td>3.49710</td>\n      <td>0.93995</td>\n      <td>1.2968</td>\n      <td>1.5437</td>\n      <td>NaN</td>\n      <td>-0.0552</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1002425</td>\n      <td>0.4068</td>\n      <td>0.47565</td>\n      <td>0.17350</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.73650</td>\n      <td>-3.2560</td>\n      <td>NaN</td>\n      <td>0.25040</td>\n      <td>...</td>\n      <td>0.9128</td>\n      <td>0.2516</td>\n      <td>0.0125</td>\n      <td>-0.0017</td>\n      <td>-0.05405</td>\n      <td>0.22090</td>\n      <td>0.1690</td>\n      <td>-4.1724</td>\n      <td>-0.1351</td>\n      <td>-1.3381</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1003685</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.50025</td>\n      <td>NaN</td>\n      <td>0.50085</td>\n      <td>0.26245</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 2924 columns</p>\n</div>"}, "metadata": {}}]}, {"cell_type": "code", "source": "pdf.to_csv(\"olink_i0.tsv\", sep=\"\\t\", index=False, header=True)", "metadata": {"trusted": true, "tags": []}, "execution_count": 19, "outputs": []}, {"cell_type": "code", "source": "%%bash\ndx upload olink_i0.tsv -p --path /Output/Olink/ --brief", "metadata": {"trusted": true, "tags": []}, "execution_count": 20, "outputs": [{"name": "stdout", "text": "file-J139qf8JbBGBqfq6B3f7YpQ0\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "field_names_2 = list(\n    data_dict_df.loc[data_dict_df[\"entity\"] == \"olink_instance_2\", \"name\"].values\n)\nprint(len(field_names_2))\nfield_names_str_2 = [f\"olink_instance_2.{f}\" for f in field_names_2]\nfield_names_query_2 = \",\".join(field_names_str_2)\ncmd_2 = [\n    \"dx\",\n    \"extract_dataset\",\n    dataset,\n    \"--fields\",\n    field_names_query_2,\n    \"--delimiter\",\n    \",\",\n    \"--output\",\n    \"extracted_data_2.sql\",\n    \"--sql\",\n]\nsubprocess.check_call(cmd_2)\nwith open(\"extracted_data_2.sql\", \"r\") as file:\n    retrieve_sql = \"\"\n    for line in file:\n        retrieve_sql += line.strip()\ntemp_df_2 = spark.sql(retrieve_sql.strip(\";\"))\npdf_2 = temp_df_2.toPandas()\nprint(pdf_2.shape)\npdf_2.head()\npdf_2.to_csv(\"olink_i2.tsv\", sep=\"\\t\", index=False, header=True)", "metadata": {"trusted": true, "tags": []}, "execution_count": 26, "outputs": [{"name": "stdout", "text": "1464\n(1172, 1464)\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "%%bash\ndx upload olink_i2.tsv -p --path /Output/Olink/ --brief", "metadata": {"trusted": true, "tags": []}, "execution_count": 27, "outputs": [{"name": "stdout", "text": "file-J139zBjJbBG7Zg4F5xXjp4f3\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "field_names_3 = list(\n    data_dict_df.loc[data_dict_df[\"entity\"] == \"olink_instance_3\", \"name\"].values\n)\nprint(len(field_names_3))\nfield_names_str_3 = [f\"olink_instance_3.{f}\" for f in field_names_3]\nfield_names_query_3 = \",\".join(field_names_str_3)\ncmd_3 = [\n    \"dx\",\n    \"extract_dataset\",\n    dataset,\n    \"--fields\",\n    field_names_query_3,\n    \"--delimiter\",\n    \",\",\n    \"--output\",\n    \"extracted_data_3.sql\",\n    \"--sql\",\n]\nsubprocess.check_call(cmd_3)\nwith open(\"extracted_data_3.sql\", \"r\") as file:\n    retrieve_sql = \"\"\n    for line in file:\n        retrieve_sql += line.strip()\ntemp_df_3 = spark.sql(retrieve_sql.strip(\";\"))\npdf_3 = temp_df_3.toPandas()\nprint(pdf_3.shape)\npdf_3.head()\npdf_3.to_csv(\"olink_i3.tsv\", sep=\"\\t\", index=False, header=True)", "metadata": {"trusted": true, "tags": []}, "execution_count": 28, "outputs": [{"name": "stdout", "text": "1464\n(1123, 1464)\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "%%bash\ndx upload olink_i3.tsv -p --path /Output/Olink/ --brief", "metadata": {"trusted": true, "tags": []}, "execution_count": 29, "outputs": [{"name": "stdout", "text": "file-J13B088JbBG6ZBpYFJ1Fp7vx\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": []}]}