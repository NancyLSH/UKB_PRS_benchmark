{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: get the EUR GWAS and keep the SNPs in EUR reference files\n",
    "# base path: /data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/White_British/gwas/\n",
    "# output base path: /data1/jiapl_group/lishuhua/project/PRS_benchmark/software/ctsleb/train/EUR/\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "def process_single_file(file_path, ref_snp, output_path):\n",
    "    ref_snp = pd.read_csv(ref_snp, sep=\"\\t\", header=None, usecols=[0, 1])\n",
    "    ref_snp.columns = [\"CHR\", \"rs_id\"]\n",
    "    if file_path.endswith(\".merged.glm.linear\"):\n",
    "        if \"BETA\" not in pd.read_csv(file_path, sep=\"\\t\", nrows=1).columns:\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", usecols=[\"#CHROM\", \"POS\", \"ALT\", \"REF\", \"OR\", \"LOG(OR)_SE\", \"P\", \"ID\"])\n",
    "            df[\"BETA\"] = np.log(df[\"OR\"])\n",
    "            df[\"SE\"] = df[\"LOG(OR)_SE\"]\n",
    "        else:\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", usecols=[\"#CHROM\", \"POS\", \"ALT\", \"REF\", \"BETA\", \"SE\", \"P\", \"ID\"])\n",
    "        # print(df.head())\n",
    "        df = df[[\"#CHROM\", \"POS\", \"ALT\", \"REF\", \"BETA\", \"SE\", \"P\", \"ID\"]]\n",
    "        df.columns = [\"CHR\", \"BP\", \"ALT\", \"REF\", \"BETA\", \"SE\", \"P\", \"rs_id\"]\n",
    "        # df.columns = [\"CHR\", \"BP\", \"rs_id\", \"REF\", \"ALT\", \"BETA\", \"SE\", \"P\"]\n",
    "        df[\"new_id\"] = df.apply(lambda row: f\"{row['rs_id']}:{row['BP']}:{row['ALT']}:{row['REF']}\" if str(row['rs_id']).startswith(\"rs\") else f\"{row['CHR']}:{row['BP']}:{row['ALT']}:{row['REF']}\", axis=1)\n",
    "        df = df[[\"CHR\", \"new_id\", \"BP\", \"ALT\", \"BETA\", \"SE\", \"P\", \"rs_id\"]]\n",
    "        # print(df.head())\n",
    "        df.columns = [\"CHR\", \"SNP\", \"BP\", \"ALT\", \"BETA\", \"SE\", \"P\", \"rs_id\"]\n",
    "        print(df.head())\n",
    "        df[\"CHR\"] = df[\"CHR\"].astype(int)\n",
    "        df[\"BP\"] = df[\"BP\"].astype(int)\n",
    "        df[\"P\"] = df[\"P\"].astype(float)\n",
    "        df[\"BETA\"] = df[\"BETA\"].astype(float)\n",
    "        df[\"SE\"] = df[\"SE\"].astype(float)\n",
    "        merged_df = pd.merge(ref_snp, df, on=[\"CHR\", \"rs_id\"], how=\"inner\")\n",
    "        if not merged_df.empty:\n",
    "            merged_df = merged_df[[\"CHR\", \"SNP\", \"BP\", \"ALT\", \"BETA\", \"SE\", \"P\", \"rs_id\"]]\n",
    "            merged_df.columns = [\"CHR\", \"SNP\", \"BP\", \"A1\", \"BETA\", \"SE\", \"P\", \"rs_id\"]\n",
    "            merged_df.to_csv(output_path, sep=\"\\t\", index=False, header=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_base_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/White_British/gwas/\"\n",
    "    output_base_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/ctsleb/train/EUR/\"\n",
    "    ref_snp_file = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/ctsleb/reference/eur_ref.txt\"\n",
    "\n",
    "    if not os.path.exists(output_base_path):\n",
    "        os.makedirs(output_base_path)\n",
    "\n",
    "    trait_dict = {\n",
    "        'p48': 'waist',\n",
    "        'p50': 'height',\n",
    "        'p102': 'pulse',\n",
    "        'p4079': 'dbp',\n",
    "        'p4080': 'sbp',\n",
    "        'p20116': 'smoke',\n",
    "        'p20117': 'drink',\n",
    "        'p21001': 'bmi',\n",
    "        'p21002': 'weight',\n",
    "        'p30000': 'wbc',\n",
    "        'p30010': 'rbc',\n",
    "        'p30020':'hb',\n",
    "        'p30080': 'plt',\n",
    "        'p30120': 'lymph',\n",
    "        'p30130': 'mono',\n",
    "        'p30140': 'neut',\n",
    "        'p30150': 'eos',\n",
    "        'p30620': 'alt',\n",
    "        'p30650': 'ast',\n",
    "        'p30670': 'bun',\n",
    "        'p30690': 'cholesterol',\n",
    "        'p30700': 'creatinine',\n",
    "        'p30730': 'ggt',\n",
    "        'p30740': 'glucose',\n",
    "        'p30760': 'hdl',\n",
    "        'p30780': 'ldl',\n",
    "        'p30870': 'triglycerides',\n",
    "        'p30880': 'ua'\n",
    "    }\n",
    "\n",
    "    for trait, name in trait_dict.items():\n",
    "        input_file = os.path.join(input_base_path, f\"{trait}_int.merged.glm.linear\")\n",
    "        output_file = os.path.join(output_base_path, f\"{name}.txt\")\n",
    "        \n",
    "        if os.path.exists(input_file):\n",
    "            process_single_file(input_file, ref_snp_file, output_file)\n",
    "            print(f\"Processed {name} and saved to {output_file}\")\n",
    "        else:\n",
    "            print(f\"Input file {input_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9303d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: Split EAS data for 5-fold cross-validation\n",
    "# EAS cross validation result: /data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/CAS/\n",
    "# EAS output: /data1/jiapl_group/lishuhua/project/PRS_benchmark/software/ctsleb/train/EAS\n",
    "# EAS reference: /data1/jiapl_group/lishuhua/software/PRS/CT_SLEB/reference/EAS/merged\n",
    "# overlap snp list: /data1/jiapl_group/lishuhua/project/PRS_benchmark/software/ctsleb/reference\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "def process_single_file(file_path, output_path, ref_snp_list):\n",
    "    # Step 1: check the rows if correct\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", header=0, low_memory=False)\n",
    "    df[\"new_id\"] = df.apply(lambda row: f\"{row['ID']}:{row['POS']}:{row['ALT']}:{row['REF']}\" if str(row['ID']).startswith(\"rs\") else f\"{row['#CHROM']}:{row['POS']}:{row['ALT']}:{row['REF']}\", axis=1)\n",
    "    columns = df.columns.tolist()\n",
    "    if \"BETA\" not in columns:\n",
    "        df[\"BETA\"] = np.log(df[\"OR\"])\n",
    "        df[\"SE\"] = df[\"LOG(OR)_SE\"]\n",
    "    df = df[[\"#CHROM\", \"new_id\", \"POS\", \"ALT\", \"BETA\", \"SE\", \"P\", \"ID\"]]\n",
    "    # Step 2: rename the columns\n",
    "    df.columns = [\"CHR\", \"SNP\", \"BP\", \"ALT\", \"BETA\", \"SE\", \"P\", \"rs_id\"]\n",
    "    df[\"CHR\"] = df[\"CHR\"].astype(int)\n",
    "    df[\"BP\"] = df[\"BP\"].astype(int)\n",
    "    df[\"P\"] = df[\"P\"].astype(float)\n",
    "    df[\"BETA\"] = df[\"BETA\"].astype(float)\n",
    "    df[\"SE\"] = df[\"SE\"].astype(float)\n",
    "    # Step 3: save the file\n",
    "    merged_df = pd.merge(ref_snp_list, df, on=[\"CHR\", \"rs_id\"], how=\"inner\")\n",
    "    if merged_df.empty:\n",
    "        print(f\"Warning: No overlapping SNPs found in {file_path}. Skipping this file.\", file=sys.stderr)\n",
    "        return\n",
    "    else:\n",
    "        print(f\"Found {len(merged_df)} overlapping SNPs in {file_path}.\")\n",
    "    # Step 4: save the merged dataframe\n",
    "    merged_df = merged_df[[\"CHR\", \"SNP\", \"BP\", \"ALT\", \"BETA\", \"SE\", \"P\", \"rs_id\"]]\n",
    "    merged_df.columns = [\"CHR\", \"SNP\", \"BP\", \"A1\", \"BETA\", \"SE\", \"P\", \"rs_id\"]\n",
    "    merged_df.to_csv(output_path, sep=\"\\t\", index=False, header=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TRAIT_LIST = ['waist', 'height', 'pulse', 'dbp', 'sbp', 'smoke', 'drink', 'bmi', 'wbc', 'rbc', 'hb', 'plt', 'lymph', 'mono', 'neut', 'eos', 'alt', 'ast', 'bun', 'cholesterol', 'creatinine', 'glucose', 'ggt', 'hdl', 'ldl', 'triglycerides', 'ua']\n",
    "    # TRAIT_LIST = ['waist']\n",
    "    eas_snp_list = pd.read_csv(\"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/ctsleb/reference/eas_ref.txt\", sep=\"\\t\", header=None, usecols=[0, 1])\n",
    "    eas_snp_list.columns = [\"CHR\", \"rs_id\"]\n",
    "    # /data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/CAS/alt/group_1/gwas/train.Pheno.glm.linear\n",
    "    for pheno in TRAIT_LIST:\n",
    "        print(f\"Processing trait: {pheno}\")\n",
    "        # 定义输入和输出目录\n",
    "        eas_input_dir = f\"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/CAS/{pheno}/\"\n",
    "        eas_output_dir = f\"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/ctsleb/train/EAS/{pheno}/\"\n",
    "        os.makedirs(eas_output_dir, exist_ok=True)\n",
    "        # 定义文件名\n",
    "        for i in range(1, 11):\n",
    "            eas_input_file = f\"{eas_input_dir}/group_{i}/gwas/train.Pheno.glm.linear\"\n",
    "            if os.path.exists(eas_input_file):\n",
    "                eas_output_file = f\"{eas_output_dir}/group_{i}.txt\"\n",
    "                print(f\"Processing EAS file: {eas_input_file} -> {eas_output_file}\")\n",
    "                process_single_file(eas_input_file, eas_output_file, eas_snp_list)\n",
    "            else:\n",
    "                eas_input_file = f\"{eas_input_dir}/group_{i}/gwas/train.Pheno.glm.logistic\"\n",
    "                if os.path.exists(eas_input_file):\n",
    "                    eas_output_file = f\"{eas_output_dir}/group_{i}.txt\"\n",
    "                    print(f\"Processing EAS file: {eas_input_file} -> {eas_output_file}\")\n",
    "                    process_single_file(eas_input_file, eas_output_file, eas_snp_list)\n",
    "                else:\n",
    "                    print(f\"Input file {eas_input_file} does not exist. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08dad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the valid and tuning dataset\n",
    "# ids_base_path: /data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/CAS/height/group_1/ids/\n",
    "# eas geno base path: /data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/CAS/geno/CAS_final/CAS_merged_qc_final\n",
    "# snp list base path: /data1/jiapl_group/lishuhua/project/PRS_benchmark/software/ctsleb/reference/\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def process_snp_list(snp_list_path, output_prefix):\n",
    "    snp_list = pd.read_csv(snp_list_path, sep='\\t', header=None)\n",
    "    snp_list.columns = [\"CHR\", \"SNP\", \"cm\", \"BP\", \"A1\", \"A2\"]\n",
    "    snp_list['check_snp'] = snp_list.apply(\n",
    "        lambda row: f\"{row['SNP']}:{row['BP']}:{row['A1']}:{row['A2']}\" if str(row['SNP']).startswith(\"rs\") else f\"{row['CHR']}:{row['BP']}:{row['A1']}:{row['A2']}\", axis=1)\n",
    "    snp_list[[\"SNP\", \"check_snp\"]].to_csv(f\"{output_prefix}/eas_update_snp_list.txt\", sep='\\t', index=False, header=False)\n",
    "    snp_list[[\"SNP\"]].to_csv(f\"{output_prefix}/eas_extract_snp_list.txt\", sep='\\t', index=False, header=False)\n",
    "\n",
    "def process_ids_file(tuning_ids_path, valid_ids_path, output_path):\n",
    "    tune_ids = pd.read_csv(tuning_ids_path, sep='\\t', header=None)\n",
    "    valid_ids = pd.read_csv(valid_ids_path, sep='\\t', header=None)\n",
    "    concat_ids = pd.concat([tune_ids, valid_ids], ignore_index=True)\n",
    "    concat_ids.to_csv(output_path, sep='\\t', index=False, header=False)\n",
    "\n",
    "def process_geno_file(snp_list_path, ids_path, geno_path, output_path):\n",
    "    cmd = f'/data1/jiapl_group/lishuhua/software/general/plink --bfile {geno_path} --extract {snp_list_path} --keep {ids_path} --make-bed --out {output_path}'\n",
    "    subprocess.run(cmd, shell=True, check=True)\n",
    "\n",
    "def update_snp_list(geno_path, snp_list_path, output_path):\n",
    "    cmd = f'/data1/jiapl_group/lishuhua/software/general/plink --bfile {geno_path} --update-name {snp_list_path} --make-bed --out {output_path}'\n",
    "    subprocess.run(cmd, shell=True, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # get the snp list\n",
    "    eas_ref_snp_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/ctsleb/reference/eas_ref.txt\"\n",
    "    eas_snp_output_prefix = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/ctsleb/reference/\"\n",
    "    eas_geno_base_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/CAS/geno/CAS_final/CAS_merged_qc_final\"\n",
    "    process_snp_list(eas_ref_snp_path, eas_snp_output_prefix)\n",
    "    extract_snp_list_path = f\"{eas_snp_output_prefix}/eas_extract_snp_list.txt\"\n",
    "    update_snp_list_path = f\"{eas_snp_output_prefix}/eas_update_snp_list.txt\"\n",
    "\n",
    "    TRAIT_LIST = ['waist', 'height', 'pulse', 'dbp', 'sbp', 'smoke', 'drink', 'bmi', 'wbc', 'rbc', 'hb', 'plt', 'lymph', 'mono', 'neut', 'eos', 'alt', 'ast', 'bun', 'cholesterol', 'creatinine', 'glucose', 'ggt', 'hdl', 'ldl', 'triglycerides', 'ua']\n",
    "    # TRAIT_LIST = ['waist']\n",
    "\n",
    "    for pheno in TRAIT_LIST:\n",
    "        print(f\"Processing trait: {pheno}\")\n",
    "        # Define paths\n",
    "        # For EUR population\n",
    "        for i in range(1, 11):\n",
    "            ids_base_path = f\"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/CAS/{pheno}/group_{i}/ids/\"\n",
    "            \n",
    "            # Process IDs file\n",
    "            tuning_ids_path = f\"{ids_base_path}/tune_ids.txt\"\n",
    "            valid_ids_path = f\"{ids_base_path}/test_ids.txt\"\n",
    "            output_ids_path = f\"{ids_base_path}/combined_ids.txt\"\n",
    "            process_ids_file(tuning_ids_path, valid_ids_path, output_ids_path)\n",
    "\n",
    "            # Process EAS genotype file\n",
    "            eas_geno_output_prefix = f\"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/ctsleb/tuning/EAS/{pheno}/\"\n",
    "            if not os.path.exists(eas_geno_output_prefix):\n",
    "                os.makedirs(eas_geno_output_prefix)\n",
    "            output_1 = f\"{eas_geno_output_prefix}/group_{i}_temp\"\n",
    "            output_2 = f\"{eas_geno_output_prefix}/group_{i}_final\"\n",
    "            process_geno_file(extract_snp_list_path, output_ids_path, eas_geno_base_path, output_1)\n",
    "            update_snp_list(output_1, update_snp_list_path, output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc836f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the duplicate SNPs in EUR and EAS GWAS files\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "EAS_gwas_base_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/ctsleb/train/EAS/\"\n",
    "EUR_gwas_base_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/ctsleb/train/EUR/\"\n",
    "\n",
    "def process_single_file(file_path, output_path):\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", header=0, low_memory=False)\n",
    "    # remove the duplicate SNPs in SNP column\n",
    "    df = df.drop_duplicates(subset=[\"SNP\"])\n",
    "    df.to_csv(output_path, sep=\"\\t\", index=False, header=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TRAIT_LIST = ['waist', 'height', 'pulse', 'dbp', 'sbp', 'smoke', 'drink', 'bmi', 'wbc', 'rbc', 'hb', 'plt', 'lymph', 'mono', 'neut', 'eos', 'alt', 'ast', 'bun', 'cholesterol', 'creatinine', 'glucose', 'ggt', 'hdl', 'ldl', 'triglycerides', 'ua']\n",
    "    # TRAIT_LIST = ['waist']\n",
    "\n",
    "    for pheno in TRAIT_LIST:\n",
    "        print(f\"Processing trait: {pheno}\")\n",
    "        # For EAS population\n",
    "        for i in range(1, 11):\n",
    "            eas_input_file = f\"{EAS_gwas_base_path}/{pheno}/group_{i}.txt\"\n",
    "            eas_output_file = f\"{EAS_gwas_base_path}/{pheno}/group_{i}_final.txt\"\n",
    "            if os.path.exists(eas_input_file):\n",
    "                process_single_file(eas_input_file, eas_output_file)\n",
    "                print(f\"Processed EAS file: {eas_input_file} -> {eas_output_file}\")\n",
    "            else:\n",
    "                print(f\"EAS input file {eas_input_file} does not exist. Skipping.\")\n",
    "\n",
    "        # For EUR population\n",
    "        eur_input_file = f\"{EUR_gwas_base_path}/{pheno}.txt\"\n",
    "        eur_output_file = f\"{EUR_gwas_base_path}/{pheno}_final.txt\"\n",
    "        if os.path.exists(eur_input_file):\n",
    "            process_single_file(eur_input_file, eur_output_file)\n",
    "            print(f\"Processed EUR file: {eur_input_file} -> {eur_output_file}\")\n",
    "        else:\n",
    "            print(f\"EUR input file {eur_input_file} does not exist. Skipping.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
