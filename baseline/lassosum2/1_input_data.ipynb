{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e53763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the EAS combine pheno and covar\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# /data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/CAS/alt/group_1/ids/combined_ids.txt\n",
    "eas_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/CAS/\"\n",
    "eas_covar_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/CAS/pheno/covariates.txt\"\n",
    "output_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/lassosum/test/EAS/\"\n",
    "\n",
    "trait_list = ['waist', 'height', 'pulse', 'dbp', 'sbp', 'smoke', 'drink', 'bmi', 'wbc', 'rbc', 'hb', 'plt', 'lymph', 'mono', 'neut', 'eos', 'alt', 'ast', 'bun', 'cholesterol', 'creatinine', 'glucose', 'ggt', 'hdl', 'ldl', 'triglycerides', 'ua']\n",
    "\n",
    "for trait in trait_list:\n",
    "    for group in range(1, 11):\n",
    "        print(f\"Processing {trait} group {group}\")\n",
    "        ids_path = os.path.join(eas_base_dir, trait, f\"group_{group}\", \"ids\", \"combined_ids.txt\")\n",
    "        pheno_path_1 = os.path.join(eas_base_dir, trait, f\"group_{group}\", \"pheno\", \"test_pheno.txt\")\n",
    "        pheno_path_2 = os.path.join(eas_base_dir, trait, f\"group_{group}\", \"pheno\", \"tune_pheno.txt\")\n",
    "        ids_df = pd.read_csv(ids_path, header=None, names=[\"FID\", \"IID\"], sep=\"\\t\")\n",
    "        pheno_df_1 = pd.read_csv(pheno_path_1, sep=\"\\t\")\n",
    "        pheno_df_2 = pd.read_csv(pheno_path_2, sep=\"\\t\")\n",
    "        pheno_df = pd.concat([pheno_df_1, pheno_df_2], ignore_index=True)\n",
    "        print(f\"IDs shape: {ids_df.shape}, Pheno shape: {pheno_df.shape}\")\n",
    "        covar_df = pd.read_csv(eas_covar_path, sep=\"\\t\")\n",
    "        ids_df[\"FID\"] = ids_df[\"FID\"].astype(str)\n",
    "        ids_df[\"IID\"] = ids_df[\"IID\"].astype(str)\n",
    "        pheno_df[\"FID\"] = pheno_df[\"FID\"].astype(str)\n",
    "        pheno_df[\"IID\"] = pheno_df[\"IID\"].astype(str)\n",
    "        covar_df[\"FID\"] = covar_df[\"FID\"].astype(str)\n",
    "        covar_df[\"IID\"] = covar_df[\"IID\"].astype(str)\n",
    "        merged_df = ids_df.merge(pheno_df, on=[\"FID\", \"IID\"]).merge(covar_df, on=[\"FID\", \"IID\"])\n",
    "        merged_pheno_df = ids_df.merge(pheno_df, on=[\"FID\", \"IID\"])\n",
    "        merged_covar_df = ids_df.merge(covar_df, on=[\"FID\", \"IID\"])\n",
    "        if merged_pheno_df.shape[0] != ids_df.shape[0]:\n",
    "            print(f\"Warning: Mismatch in number of IDs for {trait} group {group} in pheno\")\n",
    "        if merged_covar_df.shape[0] != ids_df.shape[0]:\n",
    "            print(f\"The shape of covar: {merged_covar_df.shape}, IDs shape: {ids_df.shape}\")\n",
    "            print(f\"Warning: Mismatch in number of IDs for {trait} group {group} in covar\")\n",
    "        if merged_df.shape[0] != ids_df.shape[0]:\n",
    "            print(f\"Warning: Mismatch in number of IDs for {trait} group {group}\")\n",
    "        output_path = os.path.join(output_base_dir, trait, f\"group_{group}\")\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        merged_df.to_csv(os.path.join(output_path, \"pheno_covar.txt\"), sep=\"\\t\", index=False)\n",
    "        merged_pheno_df.to_csv(os.path.join(output_path, \"pheno.txt\"), sep=\"\\t\", index=False)\n",
    "        merged_covar_df.to_csv(os.path.join(output_path, \"covar.txt\"), sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598d3c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the EUR combine pheno and covar\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# /data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/pheno/fold_1/tune_ids.txt\n",
    "eur_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/\"\n",
    "output_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/lassosum/test/EUR/\"\n",
    "covar_list = [\"age\", \"sex\", \"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\", \"PC7\", \"PC8\", \"PC9\", \"PC10\", \"PC11\", \"PC12\", \"PC13\", \"PC14\", \"PC15\", \"PC16\", \"PC17\", \"PC18\", \"PC19\", \"PC20\"]\n",
    "\n",
    "trait_dict = {\n",
    "        'p48': 'waist',\n",
    "        'p50': 'height',\n",
    "        'p102': 'pulse',\n",
    "        'p4079': 'dbp',\n",
    "        'p4080': 'sbp',\n",
    "        'p20116': 'smoke',\n",
    "        'p20117': 'drink',\n",
    "        'p21001': 'bmi',\n",
    "        'p30000': 'wbc',\n",
    "        'p30010': 'rbc',\n",
    "        'p30020':'hb',\n",
    "        'p30080': 'plt',\n",
    "        'p30120': 'lymph',\n",
    "        'p30130': 'mono',\n",
    "        'p30140': 'neut',\n",
    "        'p30150': 'eos',\n",
    "        'p30620': 'alt',\n",
    "        'p30650': 'ast',\n",
    "        'p30670': 'bun',\n",
    "        'p30690': 'cholesterol',\n",
    "        'p30700': 'creatinine',\n",
    "        'p30730': 'ggt',\n",
    "        'p30740': 'glucose',\n",
    "        'p30760': 'hdl',\n",
    "        'p30780': 'ldl',\n",
    "        'p30870': 'triglycerides',\n",
    "        'p30880': 'ua'\n",
    "    }\n",
    "\n",
    "for group in range(1, 11):\n",
    "    ids_path = os.path.join(eur_base_dir, f\"pheno/fold_{group}\", \"tune_ids.txt\")\n",
    "    covars_path = os.path.join(eur_base_dir, f\"pheno/fold_{group}\", \"tune_covar.txt\")\n",
    "    pheno_path = os.path.join(eur_base_dir, f\"pheno/fold_{group}\", \"tune_pheno.txt\")\n",
    "    ids_df = pd.read_csv(ids_path, header=None, names=[\"FID\", \"IID\"], sep=\"\\t\")\n",
    "    pheno_df = pd.read_csv(pheno_path, sep=\"\\t\")\n",
    "    covar_df = pd.read_csv(covars_path, sep=\"\\t\")\n",
    "    covar_df = covar_df[[\"FID\", \"IID\"] + covar_list]\n",
    "    print(f\"IDs shape: {ids_df.shape}, Pheno shape: {pheno_df.shape}, Covar shape: {covar_df.shape}\")\n",
    "    ids_df[\"FID\"] = ids_df[\"FID\"].astype(str)\n",
    "    ids_df[\"IID\"] = ids_df[\"IID\"].astype(str)\n",
    "    covar_df[\"FID\"] = covar_df[\"FID\"].astype(str)\n",
    "    covar_df[\"IID\"] = covar_df[\"IID\"].astype(str)\n",
    "    pheno_df[\"FID\"] = pheno_df[\"FID\"].astype(str)\n",
    "    pheno_df[\"IID\"] = pheno_df[\"IID\"].astype(str)\n",
    "    merge_df = ids_df.merge(pheno_df, on=[\"FID\", \"IID\"]).merge(covar_df, on=[\"FID\", \"IID\"])\n",
    "    if merge_df.shape[0] != ids_df.shape[0]:\n",
    "        print(f\"Warning: Mismatch in number of IDs for group {group}\")\n",
    "    for trait_id, trait in trait_dict.items():\n",
    "        print(f\"Processing {trait} group {group}\")\n",
    "        pheno_name = f\"{trait_id}_raw\"\n",
    "        if trait in ['smoke', 'drink']:\n",
    "            pheno_name = f\"{trait_id}_int\"\n",
    "        merged_df = merge_df[[\"FID\", \"IID\", pheno_name] + [col for col in covar_df.columns if col not in [\"FID\", \"IID\"]]]\n",
    "        # rename the column pheno_name to \"Pheno\"\n",
    "        merged_df.rename(columns={pheno_name: \"Pheno\"}, inplace=True)\n",
    "        output_path = os.path.join(output_base_dir, trait, f\"group_{group}\")\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        merged_df.to_csv(os.path.join(output_path, \"pheno_covar.txt\"), sep=\"\\t\", index=False)\n",
    "        merged_df[[\"FID\", \"IID\", \"Pheno\"]].to_csv(os.path.join(output_path, \"pheno.txt\"), sep=\"\\t\", index=False)\n",
    "        merged_df[[\"FID\", \"IID\"] + [col for col in covar_df.columns if col not in [\"FID\", \"IID\"]]].to_csv(os.path.join(output_path, \"covar.txt\"), sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
