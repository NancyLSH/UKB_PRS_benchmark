{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the UKB EUR ids list and split it into 10 iterations\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def check_distribution(subset_df, set_name, pheno_list):\n",
    "    print(f\"Checking distribution for {set_name} set...\")\n",
    "    for pheno in pheno_list:\n",
    "        pheno_series = subset_df[pheno].dropna()\n",
    "        class_counts = pheno_series.value_counts()\n",
    "        if class_counts.shape[0] < 2:\n",
    "            print(f\"Warning: {set_name} set for {pheno} has only one class: {class_counts.index.tolist()}\")\n",
    "            return False\n",
    "        else:\n",
    "            distribution = class_counts / class_counts.sum()\n",
    "            print(f\"{set_name} set for {pheno} class distribution:\\n{distribution}\\n\")\n",
    "    return True\n",
    "\n",
    "ukb_eur_pheno_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/pheno/trait/trait_ukb_white_british.txt\"\n",
    "ukb_eur_covar_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/pheno/covar/covars_white_british_final.tsv\"\n",
    "ukb_eur_pheno_output_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/pheno/\"\n",
    "binary_pheno_cols = ['p20116_int', 'p20117_int']\n",
    "\n",
    "pheno = pd.read_csv(ukb_eur_pheno_path, sep=\"\\t\", header=0)\n",
    "covar = pd.read_csv(ukb_eur_covar_path, sep=\"\\t\", header=0)\n",
    "pheno_cols = pheno.columns.tolist()\n",
    "pheno_raw_cols = [\"FID\", \"IID\", \"eid\"] + [col for col in pheno_cols if col.endswith(\"_raw\")]\n",
    "pheno_int_cols = [\"FID\", \"IID\", \"eid\"] + [col for col in pheno_cols if col.endswith(\"_int\")]\n",
    "covar_cols = covar.columns.tolist()\n",
    "# \"age,sex,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,PC11,PC12,PC13,PC14,PC15,PC16,PC17,PC18,PC19,PC20\"\n",
    "covar_for_gwas_cols = [\"FID\", \"IID\", \"age\", \"sex\", \"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\", \"PC7\", \"PC8\", \"PC9\", \"PC10\", \"PC11\", \"PC12\", \"PC13\", \"PC14\", \"PC15\", \"PC16\", \"PC17\", \"PC18\", \"PC19\", \"PC20\"]\n",
    "\n",
    "pheno_covar = pd.merge(pheno, covar, on=[\"FID\", \"IID\"], how=\"inner\")\n",
    "if pheno_covar.shape[0] != pheno.shape[0]:\n",
    "    print(\"pheno_covar and pheno do not match, please check!\")\n",
    "print(f'Processing 10-fold cross-validation for {pheno_covar.shape[0]} samples.')\n",
    "\n",
    "### core function: 10 fold cross-validation ###\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "all_fold_indices = [test_idx for _, test_idx in kf.split(pheno_covar)]\n",
    "print(f\"Starting 10-fold cross-validation splitting...\")\n",
    "for i in range(n_splits):\n",
    "    test_indices = all_fold_indices[i]\n",
    "    test_df = pheno_covar.iloc[test_indices]\n",
    "\n",
    "    # Split the rest into train and validation sets (80% train, 10% val)\n",
    "    tune_fold_index = (i + 1) % n_splits\n",
    "    tune_indices = all_fold_indices[tune_fold_index]\n",
    "    tune_df = pheno_covar.iloc[tune_indices]\n",
    "\n",
    "    train_fold_selection = [j for j in range(n_splits) if j != i and j != tune_fold_index]\n",
    "    train_indices = [idx for j in train_fold_selection for idx in all_fold_indices[j]]\n",
    "    train_df = pheno_covar.iloc[train_indices]\n",
    "\n",
    "    # Check distribution of binary phenotypes in each set\n",
    "    if not (check_distribution(train_df, \"Train\", binary_pheno_cols) and\n",
    "            check_distribution(tune_df, \"Validation\", binary_pheno_cols) and\n",
    "            check_distribution(test_df, \"Test\", binary_pheno_cols)):\n",
    "        print(f\"Distribution check failed for fold {i+1}. Please investigate.\")\n",
    "        continue\n",
    "    # Save the splits\n",
    "    print(f\"Saving fold {i+1} splits...\")\n",
    "    output_path = os.path.join(ukb_eur_pheno_output_path, f\"fold_{i+1}\")\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    train_df.to_csv(os.path.join(output_path, \"train_pheno_covar.txt\"), sep=\"\\t\", index=False)\n",
    "    tune_df.to_csv(os.path.join(output_path, \"tune_pheno_covar.txt\"), sep=\"\\t\", index=False)\n",
    "    test_df.to_csv(os.path.join(output_path, \"test_pheno_covar.txt\"), sep=\"\\t\", index=False)\n",
    "    train_df[pheno_cols].to_csv(os.path.join(output_path, \"train_pheno.txt\"), sep=\"\\t\", index=False)\n",
    "    tune_df[pheno_cols].to_csv(os.path.join(output_path, \"tune_pheno.txt\"), sep=\"\\t\", index=False)\n",
    "    test_df[pheno_cols].to_csv(os.path.join(output_path, \"test_pheno.txt\"), sep=\"\\t\", index=False)\n",
    "    train_df[pheno_raw_cols].to_csv(os.path.join(output_path, \"train_pheno_raw.txt\"), sep=\"\\t\", index=False)\n",
    "    train_df[pheno_int_cols].to_csv(os.path.join(output_path, \"train_pheno_int.txt\"), sep=\"\\t\", index=False)\n",
    "    tune_df[pheno_raw_cols].to_csv(os.path.join(output_path, \"tune_pheno_raw.txt\"), sep=\"\\t\", index=False)\n",
    "    tune_df[pheno_int_cols].to_csv(os.path.join(output_path, \"tune_pheno_int.txt\"), sep=\"\\t\", index=False)\n",
    "    test_df[pheno_raw_cols].to_csv(os.path.join(output_path, \"test_pheno_raw.txt\"), sep=\"\\t\", index=False)\n",
    "    test_df[pheno_int_cols].to_csv(os.path.join(output_path, \"test_pheno_int.txt\"), sep=\"\\t\", index=False)\n",
    "    train_df[covar_cols].to_csv(os.path.join(output_path, \"train_covar.txt\"), sep=\"\\t\", index=False)\n",
    "    tune_df[covar_cols].to_csv(os.path.join(output_path, \"tune_covar.txt\"), sep=\"\\t\", index=False)\n",
    "    test_df[covar_cols].to_csv(os.path.join(output_path, \"test_covar.txt\"), sep=\"\\t\", index=False)\n",
    "    train_df[covar_for_gwas_cols].to_csv(os.path.join(output_path, \"train_covar_for_gwas.txt\"), sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e7165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the phenotype missing rate in each fold in the training set\n",
    "import pandas as pd\n",
    "import os\n",
    "ukb_eur_pheno_output_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/pheno/\"\n",
    "n_splits = 10\n",
    "\n",
    "def check_missing_rate(df, set_name):\n",
    "    print(f\"Checking missing rate for {set_name} set...\")\n",
    "    # check missing rate for each phenotype column\n",
    "    missing_rates = df.isnull().mean()\n",
    "    print(f\"{set_name} set missing rates:\\n{missing_rates}\\n\")\n",
    "    return missing_rates\n",
    "\n",
    "for i in range(n_splits):\n",
    "    output_path = os.path.join(ukb_eur_pheno_output_path, f\"fold_{i+1}\")\n",
    "    train_df = pd.read_csv(os.path.join(output_path, \"train_pheno_covar.txt\"), sep=\"\\t\")\n",
    "    tune_df = pd.read_csv(os.path.join(output_path, \"tune_pheno_covar.txt\"), sep=\"\\t\")\n",
    "    test_df = pd.read_csv(os.path.join(output_path, \"test_pheno_covar.txt\"), sep=\"\\t\")\n",
    "\n",
    "    train_missing_rate = check_missing_rate(train_df, \"Train\")\n",
    "\n",
    "    # open a log file and save the printed output\n",
    "    log_file_path = os.path.join(output_path, \"missing_rate.log\")\n",
    "    with open(log_file_path, \"w\") as log_file:\n",
    "        log_file.write(f\"Fold {i+1} missing rates:\\n\")\n",
    "        log_file.write(train_missing_rate.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f2d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the phenotype missing rate in each fold in the training set\n",
    "import pandas as pd\n",
    "import os\n",
    "ukb_eur_pheno_output_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/pheno/\"\n",
    "n_splits = 10\n",
    "\n",
    "def get_df_ids_list(df, output_path, set_name):\n",
    "    print(f\"Getting IDs list for {set_name} set...\")\n",
    "    ids_list = df[[\"FID\", \"IID\"]]\n",
    "    ids_list.to_csv(os.path.join(output_path, f\"{set_name.lower()}_ids.txt\"), sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "for i in range(n_splits):\n",
    "    output_path = os.path.join(ukb_eur_pheno_output_path, f\"fold_{i+1}\")\n",
    "    train_df = pd.read_csv(os.path.join(output_path, \"train_pheno_covar.txt\"), sep=\"\\t\")\n",
    "    tune_df = pd.read_csv(os.path.join(output_path, \"tune_pheno_covar.txt\"), sep=\"\\t\")\n",
    "    test_df = pd.read_csv(os.path.join(output_path, \"test_pheno_covar.txt\"), sep=\"\\t\")\n",
    "\n",
    "    get_df_ids_list(train_df, output_path, \"train\")\n",
    "    get_df_ids_list(tune_df, output_path, \"tune\")\n",
    "    get_df_ids_list(test_df, output_path, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# eas: /data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/CAS/alt/group_1/ids\n",
    "\n",
    "def process_single_file(bfile_path, ids_path, output_path, plink_exec):\n",
    "    cmd = f\"{plink_exec} --bfile {bfile_path} --keep {ids_path} --make-bed --out {output_path}\"\n",
    "    os.system(cmd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    eur_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/pheno/\"\n",
    "    eur_geno_base_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/geno/White_British/0_sample_qc/\"\n",
    "    valid_output_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/test/\"\n",
    "    tuning_output_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/tune/\"\n",
    "    plink_exec = \"/data1/jiapl_group/lishuhua/software/general/plink\"\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        print(f'Processing fold: {i}')\n",
    "        valid_ids_path = os.path.join(eur_base_dir, f\"fold_{i}\", \"test_ids.txt\")\n",
    "        tune_ids_path = os.path.join(eur_base_dir, f\"fold_{i}\", \"tune_ids.txt\")\n",
    "        valid_output_dir = os.path.join(valid_output_base_dir, f\"fold_{i}\")\n",
    "        if not os.path.exists(valid_output_dir):\n",
    "            os.makedirs(valid_output_dir)\n",
    "        tune_output_dir = os.path.join(tuning_output_base_dir, f\"fold_{i}\")\n",
    "        if not os.path.exists(tune_output_dir):\n",
    "            os.makedirs(tune_output_dir)\n",
    "        for chrom in range(1, 23):\n",
    "            print(f'Processing chromosome: {chrom}')\n",
    "            bfile_path = os.path.join(eur_geno_base_path, f\"chr{chrom}\")\n",
    "            valid_output_prefix = os.path.join(valid_output_dir, f\"chr{chrom}\")\n",
    "            tune_output_prefix = os.path.join(tune_output_dir, f\"chr{chrom}\")\n",
    "            process_single_file(bfile_path, valid_ids_path, valid_output_prefix, plink_exec)\n",
    "            process_single_file(bfile_path, tune_ids_path, tune_output_prefix, plink_exec)\n",
    "        print(f'Finished processing fold: {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1512b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run GWAS for each fold (Binary traits)\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "def run_gwas_for_fold(fold_index, pheno_covar_path, bfile_path, pheno_list, covar_list, is_continuous, threads_num, chrom, output_path, plink_exec):\n",
    "    print(f\"Running GWAS for fold {fold_index} in chromosome {chrom}...\")\n",
    "    train_pheno_path = os.path.join(pheno_covar_path, \"train_pheno_int_dropna.txt\")\n",
    "    train_covar_path = os.path.join(pheno_covar_path, \"train_covar_for_gwas.txt\")\n",
    "    gwas_output_path = os.path.join(output_path)\n",
    "    os.makedirs(gwas_output_path, exist_ok=True)\n",
    "\n",
    "    if is_continuous:\n",
    "        print(f\"Running continuous GWAS for fold {fold_index}...\")\n",
    "        command = [\n",
    "            plink_exec,\n",
    "            \"--bfile\", bfile_path,\n",
    "            \"--pheno\", train_pheno_path,\n",
    "            \"--pheno-name\", \",\".join(pheno_list),\n",
    "            \"--covar\", train_covar_path,\n",
    "            \"--covar-name\", \",\".join(covar_list),\n",
    "            \"--glm\", \"hide-covar\", \"cols=+a1freq\",\n",
    "            \"--no-input-missing-phenotype\",\n",
    "            \"--threads\", str(threads_num),\n",
    "            \"--covar-variance-standardize\",\n",
    "            \"--out\", f'{output_path}/gwas_chr{str(chrom)}'\n",
    "        ]\n",
    "    else:\n",
    "        print(f\"Running binary GWAS for fold {fold_index}...\")\n",
    "        command = [\n",
    "            plink_exec,\n",
    "            \"--bfile\", bfile_path,\n",
    "            \"--pheno\", train_pheno_path,\n",
    "            \"--pheno-name\", \",\".join(pheno_list),\n",
    "            \"--covar\", train_covar_path,\n",
    "            \"--covar-name\", \",\".join(covar_list),\n",
    "            \"--glm\", \"hide-covar\", \"no-firth\", \"cols=+a1freq\",\n",
    "            \"--threads\", str(threads_num),\n",
    "            \"--no-input-missing-phenotype\",\n",
    "            \"--covar-variance-standardize\",\n",
    "            \"--out\", f'{output_path}/gwas_chr{str(chrom)}_binary'\n",
    "        ]\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    plink_exec = \"/data1/jiapl_group/lishuhua/software/general/plink2\"\n",
    "    eur_bfile_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/geno/White_British/0_sample_qc/\"\n",
    "    output_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/train/gwas/\"\n",
    "    pheno_covar_file_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/pheno/\"\n",
    "    trait_dict = {\n",
    "        'p48': 'waist',\n",
    "        'p50': 'height',\n",
    "        'p102': 'pulse',\n",
    "        'p4079': 'dbp',\n",
    "        'p4080': 'sbp',\n",
    "        'p20116': 'smoke',\n",
    "        'p20117': 'drink',\n",
    "        'p21001': 'bmi',\n",
    "        'p30000': 'wbc',\n",
    "        'p30010': 'rbc',\n",
    "        'p30020':'hb',\n",
    "        'p30080': 'plt',\n",
    "        'p30120': 'lymph',\n",
    "        'p30130': 'mono',\n",
    "        'p30140': 'neut',\n",
    "        'p30150': 'eos',\n",
    "        'p30620': 'alt',\n",
    "        'p30650': 'ast',\n",
    "        'p30670': 'bun',\n",
    "        'p30690': 'cholesterol',\n",
    "        'p30700': 'creatinine',\n",
    "        'p30730': 'ggt',\n",
    "        'p30740': 'glucose',\n",
    "        'p30760': 'hdl',\n",
    "        'p30780': 'ldl',\n",
    "        'p30870': 'triglycerides',\n",
    "        'p30880': 'ua'\n",
    "    }\n",
    "    pheno_cols = [f\"{key}_int\" for key in trait_dict.keys()]\n",
    "    # pheno_cols = ['p48_int']\n",
    "    # remove 'p20116_int' and 'p20117_int' from pheno_cols for continuous traits\n",
    "    binary_pheno_cols = ['p20116_int', 'p20117_int']\n",
    "    continuous_pheno_cols = [col for col in pheno_cols if col not in binary_pheno_cols]\n",
    "    covar_list = ['age', 'sex', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18', 'PC19', 'PC20']\n",
    "\n",
    "    \n",
    "    # Run GWAS for each fold\n",
    "    for fold_index in range(1, 11):\n",
    "        pheno_covar_path = os.path.join(pheno_covar_file_dir, f\"fold_{fold_index}\")\n",
    "        if not os.path.exists(os.path.join(output_dir, f\"fold_{fold_index}\")):\n",
    "            os.makedirs(os.path.join(output_dir, f\"fold_{fold_index}\"), exist_ok=True)\n",
    "        # # handle the pheno_file and remove all NA values in the pheno_list columns\n",
    "        train_pheno_path = os.path.join(pheno_covar_path, \"train_pheno_int.txt\")\n",
    "        pheno_df = pd.read_csv(train_pheno_path, sep=\"\\t\")\n",
    "        pheno_df = pheno_df.fillna('NA')\n",
    "        pheno_df.to_csv(train_pheno_path.replace(\"_int.txt\", \"_int_dropna.txt\"), sep=\"\\t\", index=False)\n",
    "        new_train_pheno_path = train_pheno_path.replace(\"_int.txt\", \"_int_dropna.txt\")\n",
    "        for chrom in range(1, 23):\n",
    "            bfile_path = os.path.join(eur_bfile_dir, f\"chr{chrom}\")\n",
    "            output_path = os.path.join(output_dir, f\"fold_{fold_index}\")\n",
    "            # run_gwas_for_fold(fold_index, pheno_covar_path, bfile_path, binary_pheno_cols, covar_list, False, 8, chrom, output_path, plink_exec)\n",
    "            run_gwas_for_fold(fold_index, pheno_covar_path, bfile_path, continuous_pheno_cols, covar_list, True, 16, chrom, output_path, plink_exec)\n",
    "\n",
    "    print(\"GWAS runs completed for all folds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacc8223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run GWAS for each fold (Binary traits)\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "def run_gwas_for_fold(fold_index, pheno_covar_path, bfile_path, pheno_list, covar_list, is_continuous, threads_num, chrom, output_path, plink_exec):\n",
    "    print(f\"Running GWAS for fold {fold_index} in chromosome {chrom}...\")\n",
    "    train_pheno_path = os.path.join(pheno_covar_path, \"train_pheno_int_dropna.txt\")\n",
    "    train_covar_path = os.path.join(pheno_covar_path, \"train_covar_for_gwas.txt\")\n",
    "    gwas_output_path = os.path.join(output_path)\n",
    "    os.makedirs(gwas_output_path, exist_ok=True)\n",
    "\n",
    "    if is_continuous:\n",
    "        print(f\"Running continuous GWAS for fold {fold_index}...\")\n",
    "        command = [\n",
    "            plink_exec,\n",
    "            \"--bfile\", bfile_path,\n",
    "            \"--pheno\", train_pheno_path,\n",
    "            \"--pheno-name\", \",\".join(pheno_list),\n",
    "            \"--covar\", train_covar_path,\n",
    "            \"--covar-name\", \",\".join(covar_list),\n",
    "            \"--glm\", \"hide-covar\", \"cols=+a1freq\",\n",
    "            \"--no-input-missing-phenotype\",\n",
    "            \"--threads\", str(threads_num),\n",
    "            \"--covar-variance-standardize\",\n",
    "            \"--out\", f'{output_path}/gwas_chr{str(chrom)}'\n",
    "        ]\n",
    "    else:\n",
    "        print(f\"Running binary GWAS for fold {fold_index}...\")\n",
    "        command = [\n",
    "            plink_exec,\n",
    "            \"--bfile\", bfile_path,\n",
    "            \"--pheno\", train_pheno_path,\n",
    "            \"--pheno-name\", \",\".join(pheno_list),\n",
    "            \"--covar\", train_covar_path,\n",
    "            \"--covar-name\", \",\".join(covar_list),\n",
    "            \"--glm\", \"hide-covar\", \"no-firth\", \"cols=+a1freq\",\n",
    "            \"--threads\", str(threads_num),\n",
    "            \"--no-input-missing-phenotype\",\n",
    "            \"--covar-variance-standardize\",\n",
    "            \"--out\", f'{output_path}/gwas_chr{str(chrom)}_binary'\n",
    "        ]\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    plink_exec = \"/data1/jiapl_group/lishuhua/software/general/plink2\"\n",
    "    eur_bfile_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/geno/White_British/0_sample_qc/\"\n",
    "    output_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/train/gwas/\"\n",
    "    pheno_covar_file_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/pheno/\"\n",
    "    trait_dict = {\n",
    "        'p48': 'waist',\n",
    "        'p50': 'height',\n",
    "        'p102': 'pulse',\n",
    "        'p4079': 'dbp',\n",
    "        'p4080': 'sbp',\n",
    "        'p20116': 'smoke',\n",
    "        'p20117': 'drink',\n",
    "        'p21001': 'bmi',\n",
    "        'p30000': 'wbc',\n",
    "        'p30010': 'rbc',\n",
    "        'p30020':'hb',\n",
    "        'p30080': 'plt',\n",
    "        'p30120': 'lymph',\n",
    "        'p30130': 'mono',\n",
    "        'p30140': 'neut',\n",
    "        'p30150': 'eos',\n",
    "        'p30620': 'alt',\n",
    "        'p30650': 'ast',\n",
    "        'p30670': 'bun',\n",
    "        'p30690': 'cholesterol',\n",
    "        'p30700': 'creatinine',\n",
    "        'p30730': 'ggt',\n",
    "        'p30740': 'glucose',\n",
    "        'p30760': 'hdl',\n",
    "        'p30780': 'ldl',\n",
    "        'p30870': 'triglycerides',\n",
    "        'p30880': 'ua'\n",
    "    }\n",
    "    pheno_cols = [f\"{key}_int\" for key in trait_dict.keys()]\n",
    "    # pheno_cols = ['p48_int']\n",
    "    # remove 'p20116_int' and 'p20117_int' from pheno_cols for continuous traits\n",
    "    binary_pheno_cols = ['p20116_int', 'p20117_int']\n",
    "    continuous_pheno_cols = [col for col in pheno_cols if col not in binary_pheno_cols]\n",
    "    covar_list = ['age', 'sex', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18', 'PC19', 'PC20']\n",
    "\n",
    "    \n",
    "    # Run GWAS for each fold\n",
    "    for fold_index in range(1, 11):\n",
    "        pheno_covar_path = os.path.join(pheno_covar_file_dir, f\"fold_{fold_index}\")\n",
    "        if not os.path.exists(os.path.join(output_dir, f\"fold_{fold_index}\")):\n",
    "            os.makedirs(os.path.join(output_dir, f\"fold_{fold_index}\"), exist_ok=True)\n",
    "        # # handle the pheno_file and remove all NA values in the pheno_list columns\n",
    "        train_pheno_path = os.path.join(pheno_covar_path, \"train_pheno_int.txt\")\n",
    "        pheno_df = pd.read_csv(train_pheno_path, sep=\"\\t\")\n",
    "        pheno_df = pheno_df.fillna('NA')\n",
    "        pheno_df.to_csv(train_pheno_path.replace(\"_int.txt\", \"_int_dropna.txt\"), sep=\"\\t\", index=False)\n",
    "        new_train_pheno_path = train_pheno_path.replace(\"_int.txt\", \"_int_dropna.txt\")\n",
    "        for chrom in range(1, 23):\n",
    "            bfile_path = os.path.join(eur_bfile_dir, f\"chr{chrom}\")\n",
    "            output_path = os.path.join(output_dir, f\"fold_{fold_index}\")\n",
    "            run_gwas_for_fold(fold_index, pheno_covar_path, bfile_path, binary_pheno_cols, covar_list, False, 16, chrom, output_path, plink_exec)\n",
    "            # run_gwas_for_fold(fold_index, pheno_covar_path, bfile_path, continuous_pheno_cols, covar_list, True, 16, chrom, output_path, plink_exec)\n",
    "\n",
    "    print(\"GWAS runs completed for all folds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d8066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run GWAS for each fold (More faster version)\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "def run_gwas_for_fold(fold_index, pheno_covar_path, bfile_path, pheno_list, covar_list, is_continuous, threads_num, chrom, output_path, plink_exec):\n",
    "    print(f\"Running GWAS for fold {fold_index} in chromosome {chrom}...\")\n",
    "    train_pheno_path = os.path.join(pheno_covar_path, \"train_pheno_int_dropna_2.txt\")\n",
    "    train_covar_path = os.path.join(pheno_covar_path, \"train_covar_for_gwas.txt\")\n",
    "    gwas_output_path = os.path.join(output_path)\n",
    "    os.makedirs(gwas_output_path, exist_ok=True)\n",
    "\n",
    "    if is_continuous:\n",
    "        print(f\"Running continuous GWAS for fold {fold_index}...\")\n",
    "        command = [\n",
    "            plink_exec,\n",
    "            \"--bfile\", bfile_path,\n",
    "            \"--pheno\", train_pheno_path,\n",
    "            \"--pheno-name\", \",\".join(pheno_list),\n",
    "            \"--covar\", train_covar_path,\n",
    "            \"--covar-name\", \",\".join(covar_list),\n",
    "            \"--glm\", \"hide-covar\", \"cols=+a1freq\",\n",
    "            \"--no-input-missing-phenotype\",\n",
    "            \"--threads\", str(threads_num),\n",
    "            \"--covar-variance-standardize\",\n",
    "            \"--out\", f'{output_path}/gwas_chr{str(chrom)}'\n",
    "        ]\n",
    "    else:\n",
    "        print(f\"Running binary GWAS for fold {fold_index}...\")\n",
    "        command = [\n",
    "            plink_exec,\n",
    "            \"--bfile\", bfile_path,\n",
    "            \"--pheno\", train_pheno_path,\n",
    "            \"--pheno-name\", \",\".join(pheno_list),\n",
    "            \"--covar\", train_covar_path,\n",
    "            \"--covar-name\", \",\".join(covar_list),\n",
    "            \"--glm\", \"hide-covar\", \"no-firth\", \"cols=+a1freq\",\n",
    "            \"--threads\", str(threads_num),\n",
    "            \"--no-input-missing-phenotype\",\n",
    "            \"--covar-variance-standardize\",\n",
    "            \"--out\", f'{output_path}/gwas_chr{str(chrom)}_binary'\n",
    "        ]\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    plink_exec = \"/data1/jiapl_group/lishuhua/software/general/plink2\"\n",
    "    eur_bfile_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/geno/White_British/0_sample_qc/\"\n",
    "    output_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/train/gwas/\"\n",
    "    pheno_covar_file_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/pheno/\"\n",
    "    trait_dict = {\n",
    "        'p48': 'waist',\n",
    "        'p50': 'height',\n",
    "        'p102': 'pulse',\n",
    "        'p4079': 'dbp',\n",
    "        'p4080': 'sbp',\n",
    "        'p20116': 'smoke',\n",
    "        'p20117': 'drink',\n",
    "        'p21001': 'bmi',\n",
    "        'p30000': 'wbc',\n",
    "        'p30010': 'rbc',\n",
    "        'p30020':'hb',\n",
    "        'p30080': 'plt',\n",
    "        'p30120': 'lymph',\n",
    "        'p30130': 'mono',\n",
    "        'p30140': 'neut',\n",
    "        'p30150': 'eos',\n",
    "        'p30620': 'alt',\n",
    "        'p30650': 'ast',\n",
    "        'p30670': 'bun',\n",
    "        'p30690': 'cholesterol',\n",
    "        'p30700': 'creatinine',\n",
    "        'p30730': 'ggt',\n",
    "        'p30740': 'glucose',\n",
    "        'p30760': 'hdl',\n",
    "        'p30780': 'ldl',\n",
    "        'p30870': 'triglycerides',\n",
    "        'p30880': 'ua'\n",
    "    }\n",
    "    pheno_cols = [f\"{key}_int\" for key in trait_dict.keys()]\n",
    "    # pheno_cols = ['p48_int']\n",
    "    # remove 'p20116_int' and 'p20117_int' from pheno_cols for continuous traits\n",
    "    binary_pheno_cols = ['p20116_int', 'p20117_int']\n",
    "    continuous_pheno_cols = [col for col in pheno_cols if col not in binary_pheno_cols]\n",
    "    covar_list = ['age', 'sex', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18', 'PC19', 'PC20']\n",
    "\n",
    "    \n",
    "    # Run GWAS for each fold\n",
    "    for fold_index in range(4, 11):\n",
    "        pheno_covar_path = os.path.join(pheno_covar_file_dir, f\"fold_{fold_index}\")\n",
    "        if not os.path.exists(os.path.join(output_dir, f\"fold_{fold_index}\")):\n",
    "            os.makedirs(os.path.join(output_dir, f\"fold_{fold_index}\"), exist_ok=True)\n",
    "        # # handle the pheno_file and remove all NA values in the pheno_list columns\n",
    "        train_pheno_path = os.path.join(pheno_covar_path, \"train_pheno_int.txt\")\n",
    "        pheno_df = pd.read_csv(train_pheno_path, sep=\"\\t\")\n",
    "        # pheno_df = pheno_df.fillna('NA')\n",
    "        pheno_df = pheno_df.dropna(subset=pheno_cols)\n",
    "        pheno_df.to_csv(train_pheno_path.replace(\"_int.txt\", \"_int_dropna_2.txt\"), sep=\"\\t\", index=False)\n",
    "        for chrom in range(1, 23):\n",
    "            bfile_path = os.path.join(eur_bfile_dir, f\"chr{chrom}\")\n",
    "            output_path = os.path.join(output_dir, f\"fold_{fold_index}\")\n",
    "            # run_gwas_for_fold(fold_index, pheno_covar_path, bfile_path, binary_pheno_cols, covar_list, False, 16, chrom, output_path, plink_exec)\n",
    "            run_gwas_for_fold(fold_index, pheno_covar_path, bfile_path, continuous_pheno_cols, covar_list, True, 16, chrom, output_path, plink_exec)\n",
    "\n",
    "    print(\"GWAS runs completed for all folds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0fb28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run GWAS for each fold in binary trait (More faster version)\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "def run_gwas_for_fold(fold_index, pheno_covar_path, bfile_path, pheno_list, covar_list, is_continuous, threads_num, chrom, output_path, plink_exec):\n",
    "    print(f\"Running GWAS for fold {fold_index} in chromosome {chrom}...\")\n",
    "    train_pheno_path = os.path.join(pheno_covar_path, \"train_pheno_int_dropna_2.txt\")\n",
    "    train_covar_path = os.path.join(pheno_covar_path, \"train_covar_for_gwas.txt\")\n",
    "    gwas_output_path = os.path.join(output_path)\n",
    "    os.makedirs(gwas_output_path, exist_ok=True)\n",
    "\n",
    "    if is_continuous:\n",
    "        print(f\"Running continuous GWAS for fold {fold_index}...\")\n",
    "        command = [\n",
    "            plink_exec,\n",
    "            \"--bfile\", bfile_path,\n",
    "            \"--pheno\", train_pheno_path,\n",
    "            \"--pheno-name\", \",\".join(pheno_list),\n",
    "            \"--covar\", train_covar_path,\n",
    "            \"--covar-name\", \",\".join(covar_list),\n",
    "            \"--glm\", \"hide-covar\", \"cols=+a1freq\",\n",
    "            \"--no-input-missing-phenotype\",\n",
    "            \"--threads\", str(threads_num),\n",
    "            \"--covar-variance-standardize\",\n",
    "            \"--out\", f'{output_path}/gwas_chr{str(chrom)}'\n",
    "        ]\n",
    "    else:\n",
    "        print(f\"Running binary GWAS for fold {fold_index}...\")\n",
    "        command = [\n",
    "            plink_exec,\n",
    "            \"--bfile\", bfile_path,\n",
    "            \"--pheno\", train_pheno_path,\n",
    "            \"--pheno-name\", \",\".join(pheno_list),\n",
    "            \"--covar\", train_covar_path,\n",
    "            \"--covar-name\", \",\".join(covar_list),\n",
    "            \"--glm\", \"hide-covar\", \"no-firth\", \"cols=+a1freq\",\n",
    "            \"--threads\", str(threads_num),\n",
    "            \"--no-input-missing-phenotype\",\n",
    "            \"--covar-variance-standardize\",\n",
    "            \"--out\", f'{output_path}/gwas_chr{str(chrom)}_binary'\n",
    "        ]\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    plink_exec = \"/data1/jiapl_group/lishuhua/software/general/plink2\"\n",
    "    eur_bfile_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/geno/White_British/0_sample_qc/\"\n",
    "    output_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/train/gwas/\"\n",
    "    pheno_covar_file_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/pheno/\"\n",
    "    trait_dict = {\n",
    "        'p48': 'waist',\n",
    "        'p50': 'height',\n",
    "        'p102': 'pulse',\n",
    "        'p4079': 'dbp',\n",
    "        'p4080': 'sbp',\n",
    "        'p20116': 'smoke',\n",
    "        'p20117': 'drink',\n",
    "        'p21001': 'bmi',\n",
    "        'p30000': 'wbc',\n",
    "        'p30010': 'rbc',\n",
    "        'p30020':'hb',\n",
    "        'p30080': 'plt',\n",
    "        'p30120': 'lymph',\n",
    "        'p30130': 'mono',\n",
    "        'p30140': 'neut',\n",
    "        'p30150': 'eos',\n",
    "        'p30620': 'alt',\n",
    "        'p30650': 'ast',\n",
    "        'p30670': 'bun',\n",
    "        'p30690': 'cholesterol',\n",
    "        'p30700': 'creatinine',\n",
    "        'p30730': 'ggt',\n",
    "        'p30740': 'glucose',\n",
    "        'p30760': 'hdl',\n",
    "        'p30780': 'ldl',\n",
    "        'p30870': 'triglycerides',\n",
    "        'p30880': 'ua'\n",
    "    }\n",
    "    pheno_cols = [f\"{key}_int\" for key in trait_dict.keys()]\n",
    "    # pheno_cols = ['p48_int']\n",
    "    # remove 'p20116_int' and 'p20117_int' from pheno_cols for continuous traits\n",
    "    binary_pheno_cols = ['p20116_int', 'p20117_int']\n",
    "    continuous_pheno_cols = [col for col in pheno_cols if col not in binary_pheno_cols]\n",
    "    covar_list = ['age', 'sex', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18', 'PC19', 'PC20']\n",
    "\n",
    "    \n",
    "    # Run GWAS for each fold\n",
    "    for fold_index in range(2, 11):\n",
    "        pheno_covar_path = os.path.join(pheno_covar_file_dir, f\"fold_{fold_index}\")\n",
    "        if not os.path.exists(os.path.join(output_dir, f\"fold_{fold_index}\")):\n",
    "            os.makedirs(os.path.join(output_dir, f\"fold_{fold_index}\"), exist_ok=True)\n",
    "        # # handle the pheno_file and remove all NA values in the pheno_list columns\n",
    "        train_pheno_path = os.path.join(pheno_covar_path, \"train_pheno_int.txt\")\n",
    "        pheno_df = pd.read_csv(train_pheno_path, sep=\"\\t\")\n",
    "        # pheno_df = pheno_df.fillna('NA')\n",
    "        pheno_df = pheno_df.dropna(subset=pheno_cols)\n",
    "        pheno_df.to_csv(train_pheno_path.replace(\"_int.txt\", \"_int_dropna_2.txt\"), sep=\"\\t\", index=False)\n",
    "        for chrom in range(1, 23):\n",
    "            bfile_path = os.path.join(eur_bfile_dir, f\"chr{chrom}\")\n",
    "            output_path = os.path.join(output_dir, f\"fold_{fold_index}\")\n",
    "            run_gwas_for_fold(fold_index, pheno_covar_path, bfile_path, binary_pheno_cols, covar_list, False, 24, chrom, output_path, plink_exec)\n",
    "            # run_gwas_for_fold(fold_index, pheno_covar_path, bfile_path, continuous_pheno_cols, covar_list, True, 16, chrom, output_path, plink_exec)\n",
    "\n",
    "    print(\"GWAS runs completed for all folds.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
