{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2eb41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import os\n",
    "\n",
    "def create_plink_split_files(\n",
    "    fam_filepath,\n",
    "    pheno_filepath,\n",
    "    output_prefix: str,\n",
    "    is_continuous: bool = False,\n",
    "    trait: str = None,\n",
    "    # trait is used to name the output files, it can be None if not needed.\n",
    "    # If is_continuous is True, the phenotype is treated as continuous; otherwise, is False for categorical traits.\n",
    "    n_splits: int = 10,\n",
    "    random_state: int = 42\n",
    "):\n",
    "    print(f\"\\n{'='*25}\\nHandling Phenotype File: {os.path.basename(str(pheno_filepath))}\\n{'='*25}\")\n",
    "    meta_data = pd.DataFrame()\n",
    "    # Step 1: Load the phenotype data\n",
    "    master_samples = pd.read_csv(fam_filepath, sep=r'\\s+', header=None, usecols=[0, 1], names=['FID', 'IID'], dtype=str)\n",
    "    # remove the header row if it exists\n",
    "    if master_samples.iloc[0, 0] == 'FID':\n",
    "        master_samples = master_samples.iloc[1:].reset_index(drop=True)\n",
    "    # Ensure FID and IID are strings\n",
    "    master_samples['FID'] = master_samples['FID'].astype(str)\n",
    "    master_samples['IID'] = master_samples['IID'].astype(str)\n",
    "    pheno_data = pd.read_csv(pheno_filepath, sep=r'\\s+', header=0)\n",
    "    pheno_data.columns = ['FID', 'IID', 'Pheno']\n",
    "    # Ensure FID and IID are strings\n",
    "    pheno_data['FID'] = pheno_data['FID'].astype(str)\n",
    "    pheno_data['IID'] = pheno_data['IID'].astype(str)\n",
    "\n",
    "    # Step 2: Merge the master samples with the phenotype data\n",
    "    merged_data = pd.merge(master_samples, pheno_data, on=['FID', 'IID'], how='left')\n",
    "\n",
    "    # Step 3: Remove samples with missing phenotypes\n",
    "    original_count = len(merged_data)\n",
    "    merged_data.dropna(subset=['Pheno'], inplace=True)\n",
    "    final_count = len(merged_data)\n",
    "\n",
    "    if original_count != final_count:\n",
    "        print(f\"Removed {original_count - final_count} samples with missing phenotypes.\")\n",
    "    \n",
    "    print(f\"Final sample count after removing missing phenotypes: {final_count}\")\n",
    "\n",
    "    y_pheno = merged_data['Pheno'].values\n",
    "    sample_ids_for_split = merged_data[['FID', 'IID']]\n",
    "    dummy_x = np.zeros((len(y_pheno), 1))  # Dummy feature matrix\n",
    "    if is_continuous:\n",
    "        print(\"Using continuous phenotype for stratification.\")\n",
    "        splitter = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        all_fold_indices = [test_idx for _, test_idx in splitter.split(dummy_x)]\n",
    "    else:\n",
    "        print(\"Using categorical phenotype for stratification.\")\n",
    "        # Ensure the phenotype is treated as categorical\n",
    "        if pd.api.types.is_float_dtype(y_pheno):\n",
    "            y_pheno = y_pheno.astype(int)\n",
    "        splitter = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        all_fold_indices = [test_idx for _, test_idx in splitter.split(dummy_x, y_pheno)]\n",
    "\n",
    "    output_dir = os.path.dirname(output_prefix)\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        test_fold_num = i\n",
    "        tune_fold_num = (i + 1) % n_splits\n",
    "        train_fold_num = [j for j in range(n_splits) if j != test_fold_num and j != tune_fold_num]\n",
    "\n",
    "        test_indices = all_fold_indices[test_fold_num]\n",
    "        tune_indices = all_fold_indices[tune_fold_num]\n",
    "        train_indices = np.concatenate([all_fold_indices[j] for j in train_fold_num])\n",
    "        if not os.path.exists(f\"{output_prefix}/group_{i+1}/ids\"):\n",
    "            os.makedirs(f\"{output_prefix}/group_{i+1}/ids\")\n",
    "        if not os.path.exists(f\"{output_prefix}/group_{i+1}/pheno\"):\n",
    "            os.makedirs(f\"{output_prefix}/group_{i+1}/pheno\")\n",
    "\n",
    "        sample_ids_for_split.iloc[train_indices].to_csv(f\"{output_prefix}/group_{i+1}/ids/train_ids.txt\", sep='\\t', index=False, header=False)\n",
    "        sample_ids_for_split.iloc[tune_indices].to_csv(f\"{output_prefix}/group_{i+1}/ids/tune_ids.txt\", sep='\\t', index=False, header=False)\n",
    "        sample_ids_for_split.iloc[test_indices].to_csv(f\"{output_prefix}/group_{i+1}/ids/test_ids.txt\", sep='\\t', index=False, header=False)\n",
    "        # Save phenotype values for each group\n",
    "        merged_data.iloc[train_indices].to_csv(f\"{output_prefix}/group_{i+1}/pheno/train_pheno.txt\", sep='\\t', index=False, header=True)\n",
    "        merged_data.iloc[tune_indices].to_csv(f\"{output_prefix}/group_{i+1}/pheno/tune_pheno.txt\", sep='\\t', index=False, header=True)\n",
    "        merged_data.iloc[test_indices].to_csv(f\"{output_prefix}/group_{i+1}/pheno/test_pheno.txt\", sep='\\t', index=False, header=True)\n",
    "\n",
    "        # save the number of three groups in each fold into a Dataframe\n",
    "        fold_counts = pd.DataFrame({\n",
    "            'Trait': trait,\n",
    "            'Total_Samples': len(sample_ids_for_split),\n",
    "            'Fold': [i + 1],\n",
    "            'Train_Count': len(train_indices),\n",
    "            'Tune_Count': len(tune_indices),\n",
    "            'Test_Count': len(test_indices)\n",
    "        })\n",
    "        meta_data = pd.concat([meta_data, fold_counts], ignore_index=True)\n",
    "    # Save the metadata DataFrame to a TSV file\n",
    "    meta_data.to_csv(f\"{output_prefix}/fold_counts.tsv\", sep='\\t', index=False, header=True)\n",
    "    print(f\"Fold counts saved to {output_prefix}/fold_counts.tsv\")\n",
    "\n",
    "\n",
    "\n",
    "    print(f'Successfully created all {n_splits} ID files for each fold in {os.path.basename(str(pheno_filepath))}.')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    eas_fam_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/CAS/geno/CAS_final/CAS_merged_qc_final.fam\"\n",
    "    eas_trait_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/CAS/pheno/trait/data/\"\n",
    "    eur_fam_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/pheno/trait/trait_ukb_white_british.txt\"\n",
    "    eur_trait_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/pheno/trait/White_British/\"\n",
    "\n",
    "    trait_dict = {\n",
    "        'p48': 'waist',\n",
    "        'p50': 'height',\n",
    "        'p102': 'pulse',\n",
    "        'p4079': 'dbp',\n",
    "        'p4080': 'sbp',\n",
    "        'p20116': 'smoke',\n",
    "        'p20117': 'drink',\n",
    "        'p21001': 'bmi',\n",
    "        'p21002': 'weight',\n",
    "        'p30000': 'wbc',\n",
    "        'p30010': 'rbc',\n",
    "        'p30020':'hb',\n",
    "        'p30080': 'plt',\n",
    "        'p30120': 'lymph',\n",
    "        'p30130': 'mono',\n",
    "        'p30140': 'neut',\n",
    "        'p30150': 'eos',\n",
    "        'p30620': 'alt',\n",
    "        'p30650': 'ast',\n",
    "        'p30670': 'bun',\n",
    "        'p30690': 'cholesterol',\n",
    "        'p30700': 'creatinine',\n",
    "        'p30730': 'ggt',\n",
    "        'p30740': 'glucose',\n",
    "        'p30760': 'hdl',\n",
    "        'p30780': 'ldl',\n",
    "        'p30870': 'triglycerides',\n",
    "        'p30880': 'ua'\n",
    "    }\n",
    "\n",
    "    for trait, name in trait_dict.items():\n",
    "        if name == \"smoke\" or name == \"drink\":\n",
    "            pheno_file = f\"{eas_trait_dir}{name}_raw.txt\"\n",
    "            is_continuous = False\n",
    "        else:\n",
    "            pheno_file = f\"{eas_trait_dir}{name}_int.txt\"\n",
    "            is_continuous = True\n",
    "        output_prefix = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/CAS/\"\n",
    "\n",
    "        create_plink_split_files(\n",
    "            fam_filepath=eas_fam_path,\n",
    "            pheno_filepath=pheno_file,\n",
    "            output_prefix=f\"{output_prefix}{name}\",\n",
    "            is_continuous=is_continuous,\n",
    "            n_splits=10,\n",
    "            trait=name,\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    for trait, name in trait_dict.items():\n",
    "        if trait == \"p20116\" or trait == \"p20117\":\n",
    "            is_continuous = False\n",
    "        else:\n",
    "            is_continuous = True\n",
    "        pheno_file = f\"{eur_trait_dir}{trait}_int.txt\"\n",
    "        output_prefix = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/\"\n",
    "\n",
    "        create_plink_split_files(\n",
    "            fam_filepath=eur_fam_path,\n",
    "            pheno_filepath=pheno_file,\n",
    "            output_prefix=f\"{output_prefix}{name}\",\n",
    "            is_continuous=is_continuous,\n",
    "            n_splits=10,\n",
    "            trait=name,\n",
    "            random_state=42\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
