{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import dxpy\n",
    "import dxdata\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import subprocess\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "dxdata.__version__\n",
    "connection = dxdata.connect()\n",
    "conf = pyspark.SparkConf().set(\"spark.kryoserializer.buffer.max\", \"2000m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed26a89",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Automatically discover dispensed database name and dataset id\n",
    "dispensed_database = dxpy.find_one_data_object(\n",
    "    classname='database', \n",
    "    name='app*', \n",
    "    folder='/', \n",
    "    name_mode='glob', \n",
    "    describe=True)\n",
    "dispensed_database_name = dispensed_database['describe']['name']\n",
    "\n",
    "dispensed_dataset = dxpy.find_one_data_object(\n",
    "    typename='Dataset', \n",
    "    name='app*.dataset', \n",
    "    folder='/', \n",
    "    name_mode='glob')\n",
    "dispensed_dataset_id = dispensed_dataset['id']\n",
    "dataset = dxdata.load_dataset(id=dispensed_dataset_id)\n",
    "dataset.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "participant = dataset['participant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd557d39",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Returns all field objects for a given UKB showcase field id\n",
    "def fields_for_id(field_id):\n",
    "    from distutils.version import LooseVersion\n",
    "    field_id = str(field_id)\n",
    "    fields = participant.find_fields(name_regex=r'^p{}(_i\\d+)?(_a\\d+)?$'.format(field_id))\n",
    "    return sorted(fields, key=lambda f: LooseVersion(f.name))\n",
    "\n",
    "# Returns all field names for a given UKB showcase field id\n",
    "def field_names_for_id(field_id):\n",
    "    return [f.name for f in fields_for_id(field_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55687c59",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# split the recommended fields into a list\n",
    "merged_fields = pd.read_csv(\"merged_fields.tsv\", sep=\"\\t\", header=0)\n",
    "merge_field_list = merged_fields[\"field_id\"].tolist()\n",
    "# cut the recommended fields list for 20 fields each group\n",
    "merge_field_list = [merge_field_list[i:i + 20] for i in range(0, len(merge_field_list), 20)]\n",
    "for i, group in enumerate(merge_field_list):\n",
    "    if i <= 13:\n",
    "        continue\n",
    "    print(f\"Retrieving fields for group {i + 1} with {len(group)} fields\")\n",
    "    # change the group astype to string\n",
    "    group = [str(x) for x in group]\n",
    "    get_ids = sum([field_names_for_id(field_id) for field_id in group], [])\n",
    "    field_names = ['eid'] + get_ids\n",
    "    df = participant.retrieve_fields(names=field_names, engine=connection)\n",
    "    data = df.toPandas()\n",
    "    display(data)\n",
    "    # save the data to a file\n",
    "    # if the file already exists, continue to the next iteration\n",
    "    data.to_csv(f'./core_category/fields_group_{i + 1}.tsv', sep='\\t', index=False, header=True)\n",
    "    # Upload the file using subprocess\n",
    "    subprocess.run([\n",
    "        \"dx\", \"upload\", f\"./core_category/fields_group_{i + 1}.tsv\",\n",
    "        \"-p\", \"--path\", \"/Output/Traits/core_category/\", \"--brief\"\n",
    "    ], check=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
