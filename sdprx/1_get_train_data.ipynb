{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36372dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: get the train data of two population\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "\n",
    "def process_single_file(file_path, output_path):\n",
    "    if file_path.endswith('.glm.linear'):\n",
    "        if \"BETA\" not in pd.read_csv(file_path, sep='\\t', nrows=1).columns:\n",
    "            df = pd.read_csv(file_path, sep='\\t', usecols=[\"ID\", \"REF\", \"ALT\", \"OR\", \"P\", \"OBS_CT\"])\n",
    "        else:\n",
    "            df = pd.read_csv(file_path, sep='\\t', usecols=[\"ID\", \"REF\", \"ALT\", \"BETA\", \"P\", \"OBS_CT\"])\n",
    "        df[\"P\"] = df[\"P\"].clip(1e-300, 1)\n",
    "        df['c'] = -stats.norm.ppf(df['P'] / 2)\n",
    "        if \"BETA\" in df.columns:\n",
    "            df['z_score'] = df['c'] * df['BETA'].apply(lambda x: -1 if x < 0 else 1)\n",
    "        else:\n",
    "            df['z_score'] = df['c'] * df['OR'].apply(lambda x: -1 if x < 1 else 1)\n",
    "        df = df[[\"ID\", \"ALT\", \"REF\", \"z_score\", \"OBS_CT\"]]\n",
    "        df.columns = [\"SNP\", \"A1\", \"A2\", \"Z\", \"N\"]\n",
    "        # remove NA\n",
    "        df = df.dropna(subset=[\"SNP\", \"N\", \"Z\", \"A1\", \"A2\"])\n",
    "        df.to_csv(output_path, sep='\\t', index=False, header=True)\n",
    "        print(f\"Processed {file_path} and saved to {output_path}\")\n",
    "    elif file_path.endswith('.glm.logistic'):\n",
    "        df = pd.read_csv(file_path, sep='\\t', usecols=[\"ID\", \"REF\", \"ALT\", \"OR\", \"P\", \"OBS_CT\"])\n",
    "        df[\"P\"] = df[\"P\"].clip(1e-300, 1)\n",
    "        df['c'] = -stats.norm.ppf(df['P'] / 2)\n",
    "        df['z_score'] = df['c'] * df['OR'].apply(lambda x: -1 if x < 1 else 1)\n",
    "        df = df[[\"ID\", \"ALT\", \"REF\", \"z_score\", \"OBS_CT\"]]\n",
    "        df.columns = [\"SNP\", \"A1\", \"A2\", \"Z\", \"N\"]\n",
    "        # remove NA\n",
    "        df = df.dropna(subset=[\"SNP\", \"N\", \"Z\", \"A1\", \"A2\"])\n",
    "        df.to_csv(output_path, sep='\\t', index=False, header=True)\n",
    "        print(f\"Processed {file_path} and saved to {output_path}\")\n",
    "    else:\n",
    "        print(f\"Unsupported file format: {file_path}\")\n",
    "\n",
    "def process_directory(dir_path, output_dir):\n",
    "    for d in os.listdir(dir_path):\n",
    "        file_path = os.path.join(dir_path, d)\n",
    "        if os.path.isfile(file_path):\n",
    "            output_path = os.path.join(output_dir, d.replace('.glm.linear', '.txt').replace('.glm.logistic', '.txt'))\n",
    "            process_single_file(file_path, output_path)\n",
    "        else:\n",
    "            print(f\"Skipping non-file item: {file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    eur_gwas_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/White_British/gwas/\"\n",
    "    eas_gwas_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/CAS/gwas/gwas/\"\n",
    "    eur_output_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/sdprx/train/EUR/\"\n",
    "    eas_output_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/sdprx/train/EAS/\"\n",
    "    if not os.path.exists(eur_output_dir):\n",
    "        os.makedirs(eur_output_dir)\n",
    "    if not os.path.exists(eas_output_dir):\n",
    "        os.makedirs(eas_output_dir)\n",
    "    process_directory(eur_gwas_dir, eur_output_dir)\n",
    "    process_directory(eas_gwas_dir, eas_output_dir)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
