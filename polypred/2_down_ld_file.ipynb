{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6f1586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the jobs.txt and get the download urls\n",
    "import pandas as pd\n",
    "\n",
    "jobs_file = pd.read_csv(\"../../../PRS_benchmark/data/software/polypred/alt_jobs.txt\", sep=\" \", header=None)\n",
    "output_dir = \"../../../PRS_benchmark/data/LD/PolyPred/\"\n",
    "npz_cmd_list = []\n",
    "gz_cmd_list = []\n",
    "check_list = []\n",
    "# display(jobs_file)\n",
    "# get the 11th column which is the download url\n",
    "urls = jobs_file[11].tolist()\n",
    "for url in urls:\n",
    "    # print(url)\n",
    "    npz_url = url + \".npz\"\n",
    "    gz_url = url + \".gz\"\n",
    "    npz_cmd = f\"wget -P {output_dir} {npz_url}\"\n",
    "    gz_cmd = f\"wget -P {output_dir} {gz_url}\"\n",
    "    npz_cmd_list.append(npz_cmd)\n",
    "    gz_cmd_list.append(gz_cmd)\n",
    "    check_item = url.replace(\"https://broad-alkesgroup-ukbb-ld.s3.amazonaws.com/UKBB_LD/\", \"\")\n",
    "    check_list.append(check_item)\n",
    "\n",
    "# write the commands to a file\n",
    "with open(\"download_commands_npz.sh\", \"w\", newline='', encoding='utf-8') as f:\n",
    "    f.write(\"#!/bin/bash\\n\")\n",
    "    for cmd in npz_cmd_list:\n",
    "        f.write(cmd)\n",
    "        f.write(\"\\n\")\n",
    "with open(\"download_commands_gz.sh\", \"w\", newline='', encoding='utf-8') as f:\n",
    "    f.write(\"#!/bin/bash\\n\")\n",
    "    for cmd in gz_cmd_list:\n",
    "        f.write(cmd)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# change check_list to a dataframe\n",
    "check_df = pd.DataFrame(check_list, columns=[\"check_item\"])\n",
    "# write the check_df to a file\n",
    "check_df.to_csv(\"check_list.txt\", sep=\"\\t\", index=False)\n",
    "\n",
    "# python3 /data1/jiapl_group/lishuhua/software/PRS/Polyfun/polyfun-master/finemapper.py --chr 1 --start 1 --end 3000001 --out /data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/2_finemapping_jobs/alt.chr1.1_3000001.gz --ld /data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/reference/UKBB_LD/chr1_1_3000001.npz --method susie --sumstats /data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/1_parquet/alt_snpvar.txt --n 336922 --memory 1 --threads 2 --max-num-causal 10\n",
    "\n",
    "# python3 /data1/jiapl_group/lishuhua/software/PRS/Polyfun/polyfun-master/finemapper.py --chr 1 --start 1 --end 3000001 --out /data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/2_finemapping_jobs/alt.chr1.1_3000001.gz --ld https://broad-alkesgroup-ukbb-ld.s3.amazonaws.com/UKBB_LD/chr1_1_3000001 --method susie --sumstats /data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/1_parquet/alt_snpvar.txt --n 336922 --memory 1 --threads 2 --max-num-causal 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234799f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all url in _jobs.txt to local path\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "jobs_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/2_finemapping_jobs/\"\n",
    "ref_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/reference/UKBB_LD/\"\n",
    "\n",
    "trait_dict = {\n",
    "    'p48': 'waist',\n",
    "    'p50': 'height',\n",
    "    'p102': 'pulse',\n",
    "    'p4079': 'dbp',\n",
    "    'p4080': 'sbp',\n",
    "    'p20116': 'smoke',\n",
    "    'p20117': 'drink',\n",
    "    'p21001': 'bmi',\n",
    "    'p30000': 'wbc',\n",
    "    'p30010': 'rbc',\n",
    "    'p30020':'hb',\n",
    "    'p30080': 'plt',\n",
    "    'p30120': 'lymph',\n",
    "    'p30130': 'mono',\n",
    "    'p30140': 'neut',\n",
    "    'p30150': 'eos',\n",
    "    'p30620': 'alt',\n",
    "    'p30650': 'ast',\n",
    "    'p30670': 'bun',\n",
    "    'p30690': 'cholesterol',\n",
    "    'p30700': 'creatinine',\n",
    "    'p30730': 'ggt',\n",
    "    'p30740': 'glucose',\n",
    "    'p30760': 'hdl',\n",
    "    'p30780': 'ldl',\n",
    "    'p30870': 'triglycerides',\n",
    "    'p30880': 'ua'\n",
    "}\n",
    "\n",
    "for trait, name in trait_dict.items():\n",
    "    create_dir = os.path.join(jobs_dir, name)\n",
    "    if not os.path.exists(create_dir):\n",
    "        os.makedirs(create_dir)\n",
    "    # check if there are any files start with name in the jobs_dir\n",
    "    for file in os.listdir(jobs_dir):\n",
    "        if file.startswith(name) and (file.endswith(\".txt\") or file.endswith(\".log\")):\n",
    "            old_path = os.path.join(jobs_dir, file)\n",
    "            new_path = os.path.join(create_dir, file)\n",
    "            os.rename(old_path, new_path)\n",
    "            print(f\"Moved {file} to {create_dir}\")\n",
    "    # for each file in the new directory, replace the url with local path\n",
    "    for job_file in os.listdir(create_dir):\n",
    "        if job_file.endswith(\"_jobs.txt\"):\n",
    "            output_name = job_file.replace(\"_jobs.txt\", \"_jobs_updated.txt\")\n",
    "            file_path = os.path.join(create_dir, job_file)\n",
    "            df = pd.read_csv(file_path, sep=\" \", header=None)\n",
    "            # replace the 11th column with local path\n",
    "            df[11] = df[11].str.replace(\"https://broad-alkesgroup-ukbb-ld.s3.amazonaws.com/UKBB_LD/\", ref_dir)\n",
    "            # df[11] = df[11].str.replace(\"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/2_finemapping_jobs/reference/UKBB_LD/\", ref_dir)\n",
    "            output_prefix = os.path.join(create_dir, output_name)\n",
    "            df.to_csv(output_prefix, sep=\" \", index=False, header=False)\n",
    "            print(f\"Updated {file_path} and saved to {output_prefix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ea6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all .npz and .gz files are in the reference directory\n",
    "import os\n",
    "import pandas as pd\n",
    "ref_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/reference/UKBB_LD/\"\n",
    "check_list = pd.read_csv(\"check_list.txt\", sep=\"\\t\")\n",
    "\n",
    "npz_files = [f for f in os.listdir(ref_dir) if f.endswith('.npz')]\n",
    "gz_files = [f for f in os.listdir(ref_dir) if f.endswith('.gz')]\n",
    "\n",
    "# check if all items in check_list are in npz_files and gz_files\n",
    "missing_npz = [item for item in check_list['check_item'] if item + '.npz' not in npz_files]\n",
    "missing_gz = [item for item in check_list['check_item'] if item + '.gz' not in gz_files]\n",
    "\n",
    "if missing_npz:\n",
    "    print(f\"Missing .npz files num: {len(missing_npz)}\")\n",
    "\n",
    "if missing_gz:\n",
    "    print(f\"Missing .gz files num: {len(missing_gz)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
