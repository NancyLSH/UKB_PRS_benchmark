{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e70d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Get the columns from the GWAS file and process them (0_get_train_input.py)\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "def process_single_job(\n",
    "    gwas_filepath,\n",
    "    output_prefix,\n",
    "    trait_name,\n",
    "):\n",
    "    print(f\"Processing {trait_name} from {gwas_filepath}\")\n",
    "    if \"BETA\" not in pd.read_csv(gwas_filepath, sep=\"\\t\", nrows=1).columns:\n",
    "        df = pd.read_csv(gwas_filepath, sep=\"\\t\", usecols=[\"#CHROM\",\"POS\", \"ID\", \"REF\", \"ALT\", \"OR\", \"P\", \"OBS_CT\", \"A1_FREQ\"])\n",
    "    else:\n",
    "        df = pd.read_csv(gwas_filepath, sep=\"\\t\", usecols=[\"#CHROM\", \"POS\", \"ID\", \"REF\", \"ALT\", \"BETA\", \"P\", \"OBS_CT\", \"A1_FREQ\"])\n",
    "    df[\"P\"] = df[\"P\"].clip(lower=1e-300, upper=1.0)\n",
    "    df['c'] = -stats.norm.ppf(df['P'] / 2)\n",
    "    if \"BETA\" in df.columns:\n",
    "        df['z_score'] = df['c'] * df['BETA'].apply(lambda x: -1 if x < 0 else 1)\n",
    "    else:\n",
    "        df['z_score'] = df['c'] * df['OR'].apply(lambda x: -1 if x < 1 else 1)\n",
    "    df = df[[\"#CHROM\", \"ID\", \"POS\", \"ALT\", \"REF\", \"z_score\", \"OBS_CT\", \"A1_FREQ\"]]\n",
    "    df.columns = [\"CHR\", \"SNP\", \"BP\", \"A1\", \"A2\", \"Z\", \"N\", \"A1FREQ\"]\n",
    "    df = df.dropna(subset=[\"SNP\", \"N\", \"Z\", \"A1\", \"A2\"])\n",
    "    # remove duplicates\n",
    "    df = df.drop_duplicates(subset=[\"SNP\", \"CHR\", \"BP\"])\n",
    "    df.to_csv(output_prefix, sep='\\t', index=False, header=True)\n",
    "    print(f\"Processed {trait_name} and saved to {output_prefix}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trait_dict = {\n",
    "        'p48': 'waist',\n",
    "        'p50': 'height',\n",
    "        'p102': 'pulse',\n",
    "        'p4079': 'dbp',\n",
    "        'p4080': 'sbp',\n",
    "        'p20116': 'smoke',\n",
    "        'p20117': 'drink',\n",
    "        'p21001': 'bmi',\n",
    "        'p30000': 'wbc',\n",
    "        'p30010': 'rbc',\n",
    "        'p30020':'hb',\n",
    "        'p30080': 'plt',\n",
    "        'p30120': 'lymph',\n",
    "        'p30130': 'mono',\n",
    "        'p30140': 'neut',\n",
    "        'p30150': 'eos',\n",
    "        'p30620': 'alt',\n",
    "        'p30650': 'ast',\n",
    "        'p30670': 'bun',\n",
    "        'p30690': 'cholesterol',\n",
    "        'p30700': 'creatinine',\n",
    "        'p30730': 'ggt',\n",
    "        'p30740': 'glucose',\n",
    "        'p30760': 'hdl',\n",
    "        'p30780': 'ldl',\n",
    "        'p30870': 'triglycerides',\n",
    "        'p30880': 'ua'\n",
    "    }\n",
    "    sumstats_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/White_British/gwas/\"\n",
    "    output_base_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/0_cleaned/\"\n",
    "    # p102_int.merged.glm.linear\n",
    "    for trait, name in trait_dict.items():\n",
    "        sumstats_filepath = os.path.join(sumstats_dir, f\"{trait}_int.merged.glm.linear\")\n",
    "        process_single_job(\n",
    "            gwas_filepath=sumstats_filepath,\n",
    "            output_prefix=os.path.join(output_base_path, f\"{name}.txt\"),\n",
    "            trait_name=name\n",
    "        )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28fe218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: munged sumstats using GWAS file (1_munge_sumstats.py)\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "def process_single_job(\n",
    "    sumstats_filepath,\n",
    "    output_prefix,\n",
    "    polyfun_exec\n",
    "):\n",
    "    command = [\n",
    "        \"python\", polyfun_exec,\n",
    "        \"--sumstats\", sumstats_filepath,\n",
    "        \"--out\", output_prefix,\n",
    "    ]\n",
    "    # Run the command\n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running command: {' '.join(command)}\")\n",
    "        print(e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trait_list = ['waist', 'height', 'pulse', 'dbp', 'sbp', 'smoke', 'drink', 'bmi',\n",
    "                  'wbc', 'rbc', 'hb', 'plt', 'lymph', 'mono', 'neut', 'eos',\n",
    "                  'alt', 'ast', 'bun', 'cholesterol', 'creatinine', 'ggt',\n",
    "                  'glucose', 'hdl', 'ldl', 'triglycerides', 'ua']\n",
    "    sumstats_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/0_cleaned/\"\n",
    "    output_base_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/1_parquet/\"\n",
    "    polypred_exec = \"/data1/jiapl_group/lishuhua/software/PRS/Polyfun/polyfun-master/munge_polyfun_sumstats.py\"\n",
    "    for trait in trait_list:\n",
    "        sumstats_filepath = os.path.join(sumstats_dir, f\"{trait}.txt\")\n",
    "        output_prefix = os.path.join(output_base_path, f\"{trait}.txt\")\n",
    "        process_single_job(\n",
    "            sumstats_filepath=sumstats_filepath,\n",
    "            output_prefix=output_prefix,\n",
    "            polyfun_exec=polypred_exec\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcedcafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: created .snpvar file from .txt file (1_add_snpvar.py)\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "def process_single_job(\n",
    "    sumstats_filepath,\n",
    "    output_prefix,\n",
    "    polyfun_exec\n",
    "):\n",
    "    command = [\n",
    "        \"python\", polyfun_exec,\n",
    "        \"--sumstats\", sumstats_filepath,\n",
    "        \"--allow-missing\",\n",
    "        \"--out\", output_prefix,\n",
    "    ]\n",
    "    # Run the command\n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running command: {' '.join(command)}\")\n",
    "        print(e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trait_list = ['waist', 'height', 'pulse', 'dbp', 'sbp', 'smoke', 'drink', 'bmi',\n",
    "                  'wbc', 'rbc', 'hb', 'plt', 'lymph', 'mono', 'neut', 'eos',\n",
    "                  'alt', 'ast', 'bun', 'cholesterol', 'creatinine', 'ggt',\n",
    "                  'glucose', 'hdl', 'ldl', 'triglycerides', 'ua']\n",
    "    sumstats_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/1_parquet/\"\n",
    "    output_base_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/1_parquet/\"\n",
    "    polypred_exec = \"/data1/jiapl_group/lishuhua/software/PRS/Polyfun/polyfun-master/extract_snpvar.py\"\n",
    "    for trait in trait_list:\n",
    "        sumstats_filepath = os.path.join(sumstats_dir, f\"{trait}.txt\")\n",
    "        output_prefix = os.path.join(output_base_path, f\"{trait}_snpvar.txt\")\n",
    "        process_single_job(\n",
    "            sumstats_filepath=sumstats_filepath,\n",
    "            output_prefix=output_prefix,\n",
    "            polyfun_exec=polypred_exec\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21e99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: created finemapping jobs using .snpvar file (2_create_jobs.py)\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "def process_single_job(\n",
    "    sumstats_filepath,\n",
    "    output_prefix,\n",
    "    jobs_output_prefix,\n",
    "    polyfun_exec\n",
    "):\n",
    "    command = [\n",
    "        \"python\", polyfun_exec,\n",
    "        \"--sumstats\", sumstats_filepath,\n",
    "        \"--method\", \"susie\",\n",
    "        \"--n\", \"336922\",\n",
    "        \"--max-num-causal\", \"10\",\n",
    "        \"--jobs-file\", jobs_output_prefix,\n",
    "        \"--memory\", \"3\",\n",
    "        \"--threads\", \"12\",\n",
    "        \"--out\", output_prefix,\n",
    "    ]\n",
    "    # Run the command\n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running command: {' '.join(command)}\")\n",
    "        print(e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trait_list = ['waist', 'height', 'pulse', 'dbp', 'sbp', 'smoke', 'drink', 'bmi',\n",
    "                  'wbc', 'rbc', 'hb', 'plt', 'lymph', 'mono', 'neut', 'eos',\n",
    "                  'alt', 'ast', 'bun', 'cholesterol', 'creatinine', 'ggt',\n",
    "                  'glucose', 'hdl', 'ldl', 'triglycerides', 'ua']\n",
    "    sumstats_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/1_parquet/\"\n",
    "    output_base_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/2_finemapping_jobs/\"\n",
    "    polypred_exec = \"/data1/jiapl_group/lishuhua/software/PRS/Polyfun/polyfun-master/create_finemapper_jobs.py\"\n",
    "    for trait in trait_list:\n",
    "        sumstats_filepath = os.path.join(sumstats_dir, f\"{trait}_snpvar.txt\")\n",
    "        output_prefix = os.path.join(output_base_path, f\"{trait}/job\")\n",
    "        if not os.path.exists(os.path.dirname(output_prefix)):\n",
    "            os.makedirs(os.path.dirname(output_prefix))\n",
    "        jobs_output_prefix = os.path.join(output_base_path, f\"{trait}/{trait}_jobs.txt\")\n",
    "        process_single_job(\n",
    "            sumstats_filepath=sumstats_filepath,\n",
    "            output_prefix=output_prefix,\n",
    "            jobs_output_prefix=jobs_output_prefix,\n",
    "            polyfun_exec=polypred_exec\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df1e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "def process_single_job(\n",
    "    sumstats_filepath,\n",
    "    output_prefix,\n",
    "    temp_prefix,\n",
    "    polyfun_exec\n",
    "):\n",
    "    command = [\n",
    "        \"python\", polyfun_exec,\n",
    "        \"--sumstats\", sumstats_filepath,\n",
    "        \"--adjust-beta-freq\",\n",
    "        \"--out-prefix\", temp_prefix,\n",
    "        \"--out\", output_prefix\n",
    "    ]\n",
    "    # Run the command\n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running command: {' '.join(command)}\")\n",
    "        print(e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # trait_list = ['waist', 'height', 'pulse', 'dbp', 'sbp', 'smoke', 'drink', 'bmi',\n",
    "    #               'wbc', 'rbc', 'hb', 'plt', 'lymph', 'mono', 'neut', 'eos',\n",
    "    #               'alt', 'ast', 'bun', 'cholesterol', 'creatinine', 'ggt',\n",
    "    #               'glucose', 'hdl', 'ldl', 'triglycerides', 'ua']\n",
    "    trait_list = ['alt', 'ast', 'bmi']\n",
    "    sumstats_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/1_parquet/\"\n",
    "    temp_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/2_finemapping_jobs/\"\n",
    "    output_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/3_aggregate/\"\n",
    "    polypred_exec = \"/data1/jiapl_group/lishuhua/software/PRS/Polyfun/polyfun-master/aggregate_finemapper_results.py\"\n",
    "    for trait in trait_list:\n",
    "        sumstats_filepath = os.path.join(sumstats_dir, f\"{trait}_snpvar.txt\")\n",
    "        temp_prefix = os.path.join(temp_dir, f\"{trait}/job\")\n",
    "        output_prefix = os.path.join(output_dir, f\"{trait}.txt\")\n",
    "        \n",
    "        process_single_job(\n",
    "            sumstats_filepath=sumstats_filepath,\n",
    "            output_prefix=output_prefix,\n",
    "            temp_prefix=temp_prefix,\n",
    "            polyfun_exec=polypred_exec\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e932bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the polypred run successfully\n",
    "# find . -type f -name \"*.gz\" | wc -l\n",
    "# find . -type f -name \"*.gz.log\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a4770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "python /data1/jiapl_group/lishuhua/software/PRS/Polyfun/polyfun-master/aggregate_finemapper_results.py --sumstats /data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/1_parquet/alt_snpvar.txt --adjust-beta-freq --out-prefix /data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/2_finemapping_jobs/alt --out /data1/jiapl_group/lishuhua/project/PRS_benchmark/software/polypred/train/EUR/3_aggregate/alt.txt"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
