{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f1a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "bbj_info_path = \"/data1/jiapl_group/lishuhua/BBJ/bbj_info.tsv\"\n",
    "gwas_base_dir = \"/data1/jiapl_group/lishuhua/BBJ/general/\"\n",
    "output_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/BBJ/r2_with_ukb/data/\"\n",
    "\n",
    "def get_summary_stats(gwas_file, n_sample, output_path, chunksize=500000):\n",
    "    required_columns = [\"SNP\", \"ALLELE1\", \"ALLELE0\", \"A1FREQ\", \"BETA\", \"SE\"]\n",
    "    chunk_iter = pd.read_csv(gwas_file, sep=\"\\t\", usecols=required_columns, chunksize=chunksize)\n",
    "    is_first_chunk = True\n",
    "    for chunk in chunk_iter:\n",
    "        chunk.rename(columns={\"SNP\": \"rsid\", \"ALLELE1\": \"a2\", \"ALLELE0\": \"a1\", \"A1FREQ\": \"af\", \"BETA\": \"beta\"}, inplace=True)\n",
    "        chunk[\"N\"] = n_sample\n",
    "        chunk = chunk[[\"rsid\", \"a1\", \"a2\", \"af\", \"N\", \"beta\", \"SE\"]]\n",
    "        if is_first_chunk:\n",
    "            chunk.to_csv(output_path, sep=\"\\t\", index=False, mode='w', header=True)\n",
    "            is_first_chunk = False\n",
    "        else:\n",
    "            chunk.to_csv(output_path, sep=\"\\t\", index=False, mode='a', header=False)\n",
    "\n",
    "bbj_info = pd.read_csv(bbj_info_path, sep=\"\\t\")\n",
    "for _, row in bbj_info.iterrows():\n",
    "    trait = row['trait']\n",
    "    n_sample = int(row[\"n\"])\n",
    "    file_prefix = row[\"file_prefix\"]\n",
    "    gwas_file_dir = os.path.join(gwas_base_dir, f\"hum0197.v3.BBJ.{file_prefix}.v1/\")\n",
    "    gwas_file = None\n",
    "    for file_name in os.listdir(gwas_file_dir):\n",
    "        if file_name.endswith(\".auto.txt\") and file_name.startswith(\"GWASsummary_\"):\n",
    "            gwas_file = os.path.join(gwas_file_dir, file_name)\n",
    "            break\n",
    "    if gwas_file is None:\n",
    "        print(f\"GWAS file not found for trait {trait}\")\n",
    "        continue\n",
    "    output_path = os.path.join(output_base_dir, f\"{trait}.txt\")\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Output file already exists for trait {trait}, skipping...\")\n",
    "        continue\n",
    "    print(f\"Processing trait {trait}...\")\n",
    "    get_summary_stats(gwas_file, n_sample, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a77e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "eas_gwas_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/BBJ/r2_with_ukb/data/\"\n",
    "eur_gwas_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/popcorn/gwas/EUR/\"\n",
    "output_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/BBJ/r2_with_ukb/res/\"\n",
    "score_file_path = \"/data1/jiapl_group/lishuhua/software/general/Popcorn-master/score/EUR_EAS_all_gen_eff.cscore\"\n",
    "\n",
    "trait_list = ['waist', 'height', 'pulse', 'dbp', 'sbp', 'smoke', 'drink', 'bmi', 'wbc', 'rbc', 'hb', 'plt', 'lymph', 'mono', 'neut', 'eos', 'alt', 'ast', 'bun', 'cholesterol', 'creatinine', 'glucose', 'ggt', 'hdl', 'ldl', 'triglycerides', 'ua']\n",
    "\n",
    "for trait_name in trait_list:\n",
    "    eas_sumstats_path = os.path.join(eas_gwas_base_dir, f\"{trait_name}.txt\")\n",
    "    eur_sumstats_path = os.path.join(eur_gwas_base_dir, f\"{trait_name}.txt\")\n",
    "    if not os.path.exists(eas_sumstats_path):\n",
    "        print(f\"EAS summary stats file not found for trait {trait_name}, skipping...\")\n",
    "        continue\n",
    "    if not os.path.exists(eur_sumstats_path):\n",
    "        print(f\"EUR summary stats file not found for trait {trait_name}, skipping...\")\n",
    "        continue\n",
    "    output_path = os.path.join(output_base_dir, f\"{trait_name}.txt\")\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Output file already exists for trait {trait_name}, skipping...\")\n",
    "        continue\n",
    "    print(f\"Processing trait {trait_name}...\")\n",
    "    cmd = f\"popcorn fit -v 1 --cfile {score_file_path} --gen_effect --sfile1 {eur_sumstats_path} --sfile2 {eas_sumstats_path} {output_path}\"\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f24109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def parse_popcorn_output(file_path):\n",
    "    \"\"\"解析单个Popcorn输出文件并提取所需数据。\"\"\"\n",
    "    results = []\n",
    "    trait_name = os.path.basename(file_path).replace('.txt', '')\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    # 跳过表头\n",
    "    for line in lines[1:]:\n",
    "        parts = line.split()\n",
    "        if not parts:\n",
    "            continue\n",
    "        \n",
    "        parameter = parts[0]\n",
    "        if parameter in [\"h1^2\", \"h2^2\", \"pge\"]:\n",
    "            value = float(parts[1])\n",
    "            se = float(parts[2])\n",
    "            results.append({\n",
    "                \"Trait\": trait_name,\n",
    "                \"Parameter\": parameter,\n",
    "                \"Value\": value,\n",
    "                \"SE\": se\n",
    "            })\n",
    "            \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数，遍历目录，处理文件并保存为TSV。\"\"\"\n",
    "    # *** 请修改为您的Popcorn结果文件所在的目录 ***\n",
    "    input_directory = '/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/BBJ/r2_with_ukb/res/' \n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    print(f\"开始扫描目录: {os.path.abspath(input_directory)}\")\n",
    "    \n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(input_directory, filename)\n",
    "            print(f\"正在处理文件: {filename}\")\n",
    "            try:\n",
    "                file_results = parse_popcorn_output(file_path)\n",
    "                all_results.extend(file_results)\n",
    "            except Exception as e:\n",
    "                print(f\"处理文件 {filename} 时出错: {e}\")\n",
    "\n",
    "    if not all_results:\n",
    "        print(\"警告: 未找到任何有效的Popcorn结果文件或未能提取任何数据。\")\n",
    "        return\n",
    "\n",
    "    # 将结果转换为DataFrame并保存为TSV文件\n",
    "    df = pd.DataFrame(all_results)\n",
    "    output_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/BBJ/r2_with_ukb/res/popcorn_results_bbj_ukb.tsv\"\n",
    "    df.to_csv(output_path, sep='\\t', index=False)\n",
    "    \n",
    "    print(f\"\\n处理完成！数据已成功保存到: {output_path}\")\n",
    "    print(\"文件内容预览:\")\n",
    "    print(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
