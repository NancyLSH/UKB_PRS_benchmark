{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b385b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip file and briefly process\n",
    "# unzip \"hum0197.v3.BBJ.*.zip\"\n",
    "# find hum0197.v3.BBJ.*/ -type f -name \"*.auto.txt.gz\" -exec gunzip -f {} +\n",
    "# a dict of BBJ GWAS information\n",
    "import pandas as pd\n",
    "\n",
    "bbj_info = pd.read_csv(\"bbj_dict.txt\", sep=r\"\\s+\", header=None, names=[\"trait\", \"n\", \"file\"])\n",
    "bbj_info[\"file_prefix\"] = bbj_info[\"file\"].apply(lambda x: x.replace(\".v1.zip\", \"\").replace(\"hum0197.v3.BBJ.\", \"\"))\n",
    "bbj_info = bbj_info[[\"trait\", \"n\", \"file_prefix\"]]\n",
    "# display(bbj_info)\n",
    "bbj_info.to_csv(\"bbj_info.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc175ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Step 1: convert gwas file into .sumstats files\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "munge_script = \"/data1/jiapl_group/lishuhua/software/general/ldsc/munge_sumstats.py\"\n",
    "bbj_info_path = \"/data1/jiapl_group/lishuhua/BBJ/bbj_info.tsv\"\n",
    "merge_allele_file_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/snpinfo_mult_1kg_hm3\"\n",
    "gwas_base_dir = \"/data1/jiapl_group/lishuhua/BBJ/general/\"\n",
    "output_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/BBJ/munged/\"\n",
    "temp_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/BBJ/temp/\"\n",
    "\n",
    "# 检查路径是否存在，如果不存在则创建\n",
    "if not os.path.exists(output_base_dir):\n",
    "    os.makedirs(output_base_dir)\n",
    "if not os.path.exists(temp_base_dir):\n",
    "    os.makedirs(temp_base_dir)\n",
    "\n",
    "def process_gwas_file(gwas_file, merge_allele_file_list, output_file, chunksize=500000):\n",
    "    required_columns = [\"SNP\", \"ALLELE1\", \"ALLELE0\", \"BETA\", \"SE\", \"P_BOLT_LMM_INF\"]\n",
    "    chunk_iter = pd.read_csv(gwas_file, sep=\"\\t\", chunksize=chunksize, usecols=required_columns)\n",
    "    is_first_chunk = True\n",
    "    # 循环处理每个块\n",
    "    for chunk in chunk_iter:\n",
    "        # 为当前块添加 'N' 列\n",
    "        chunk.rename(columns={\"ALLELE1\": \"A2\", \"ALLELE0\": \"A1\", \"P_BOLT_LMM_INF\": \"P\"}, inplace=True)\n",
    "        chunk['N'] = n_sample\n",
    "        chunk = chunk[chunk[\"SNP\"].isin(merge_allele_file_list)]\n",
    "        if is_first_chunk:\n",
    "            # 第一个块：使用 'w' 模式（写入），并包含表头\n",
    "            chunk.to_csv(output_file, sep=\"\\t\", index=False, mode='w', header=True)\n",
    "            is_first_chunk = False # 修改标志位\n",
    "        else:\n",
    "            # 后续的块：使用 'a' 模式（追加），并且不包含表头\n",
    "            chunk.to_csv(output_file, sep=\"\\t\", index=False, mode='a', header=False)\n",
    "\n",
    "def convert_to_sumstats(input_file, output_file, n_sample):\n",
    "    # 使用 .format() 替换 f-string\n",
    "    command = \"python {munge_script} --sumstats {input_file} --N {n_sample} --merge-alleles {merge_allele_file_path} --out {output_file}\".format(\n",
    "        munge_script=munge_script,\n",
    "        input_file=input_file,\n",
    "        n_sample=n_sample,\n",
    "        merge_allele_file_path=merge_allele_file_path,\n",
    "        output_file=output_file\n",
    "    )\n",
    "    os.system(command)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bbj_info = pd.read_csv(bbj_info_path, sep=\"\\t\")\n",
    "    merge_allele_file = pd.read_csv(merge_allele_file_path, sep=\"\\t\")\n",
    "    merge_allele_file_list = set(merge_allele_file[\"SNP\"].tolist())\n",
    "    # 在Python 2中，iterrows()返回的是(index, Series)对，用法不变\n",
    "    for _, row in bbj_info.iterrows():\n",
    "        trait = row[\"trait\"]\n",
    "        n_sample = int(row[\"n\"])\n",
    "        file_prefix = row[\"file_prefix\"]\n",
    "        \n",
    "        # 使用 .format() 替换 f-string\n",
    "        gwas_file_dir = os.path.join(gwas_base_dir, \"hum0197.v3.BBJ.{0}.v1/\".format(file_prefix))\n",
    "        \n",
    "        # search the .auto.txt file in the directory\n",
    "        gwas_file = None\n",
    "        for file_name in os.listdir(gwas_file_dir):\n",
    "            if file_name.endswith(\".auto.txt\") and file_name.startswith(\"GWASsummary_\"):\n",
    "                gwas_file = os.path.join(gwas_file_dir, file_name)\n",
    "                break\n",
    "        \n",
    "        # 使用 .format() 替换 f-string\n",
    "        temp_output_file = os.path.join(temp_base_dir, \"{0}.tsv\".format(trait))\n",
    "        final_output_file = os.path.join(output_base_dir, \"{0}\".format(trait))\n",
    "        \n",
    "        # 使用 print() 函数 (因为我们从 __future__ 导入了它)\n",
    "        print(\"Processing {0}...\".format(gwas_file))\n",
    "        process_gwas_file(gwas_file, merge_allele_file_list, temp_output_file)\n",
    "        convert_to_sumstats(temp_output_file, final_output_file, n_sample)\n",
    "        print(\"Saved munged sumstats to {0}\".format(final_output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "munged_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/BBJ/munged/\"\n",
    "eas_ld_ref_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/EAS_baselineLD/baselineLD.\"\n",
    "eas_w_ld_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/EAS_ldscores/weights.EAS.hm3_noMHC.\"\n",
    "output_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/BBJ/h2/\"\n",
    "munge_script = \"/data1/jiapl_group/lishuhua/software/general/ldsc/ldsc.py\"\n",
    "\n",
    "def compute_h2(trait, munged_sumstats, ld_ref, w_ld, out_dir):\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    out_file = os.path.join(out_dir, trait)\n",
    "    command = \"python {munged_script} --h2 {munged_sumstats} --ref-ld-chr {ld_ref} --w-ld-chr {w_ld} --out {out_file}\".format(\n",
    "        munged_script=munge_script,\n",
    "        munged_sumstats=munged_sumstats,\n",
    "        ld_ref=ld_ref,\n",
    "        w_ld=w_ld,\n",
    "        out_file=out_file\n",
    "    )\n",
    "    os.system(command)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(output_base_dir):\n",
    "        os.makedirs(output_base_dir)\n",
    "    search_pattern = os.path.join(munged_base_dir, \"*.sumstats.gz\")\n",
    "    munged_files = glob.glob(search_pattern)\n",
    "    for munged_file in munged_files:\n",
    "        trait = os.path.basename(munged_file).replace(\".sumstats.gz\", \"\")\n",
    "        print(\"Computing h2 for {0}...\".format(trait))\n",
    "        compute_h2(trait, munged_file, eas_ld_ref_path, eas_w_ld_path, output_base_dir)\n",
    "        print(\"Saved h2 results for {0}.\".format(trait))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8377bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_h2_from_logs(folder_path):\n",
    "    pattern = re.compile(r\"Total Observed scale h2:\\s*([\\d.]+)\\s*\\(([\\d.]+)\\)\")\n",
    "    results = []\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder {folder_path} does not exist.\")\n",
    "        return results\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".log\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            trait = filename.replace(\".log\", \"\")\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    for line_num, line in enumerate(f, start=1):\n",
    "                        match = pattern.search(line)\n",
    "                        if match:\n",
    "                            h2_value = float(match.group(1))\n",
    "                            se_value = float(match.group(2))\n",
    "                            results.append((trait, h2_value, se_value))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_path} on line {line_num}: {e}\")\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    h2_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/BBJ/h2/\"\n",
    "    h2_results = extract_h2_from_logs(h2_dir)\n",
    "    h2_df = pd.DataFrame(h2_results, columns=[\"trait\", \"h2\", \"se\"])\n",
    "    h2_df.to_csv(\"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/BBJ/bbj_h2_results.tsv\", sep=\"\\t\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
