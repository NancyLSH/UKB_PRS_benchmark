{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b021e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the snp_list.txt that use to extract the SNPs from the bfile\n",
    "# awk '{print $2}' /data1/jiapl_group/lishuhua/software/PRS/PROSPER/reference/ref_bim.txt > /data1/jiapl_group/lishuhua/software/PRS/PROSPER/reference/snp_list.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f86dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# eas: /data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/CAS/alt/group_1/ids\n",
    "\n",
    "def process_single_file(bfile_path, ids_path, pheno_path, snp_list_path, output_path, plink_exec):\n",
    "    cmd = f\"{plink_exec} --bfile {bfile_path} --keep {ids_path} --extract {snp_list_path} --pheno {pheno_path} --make-bed --out {output_path}\"\n",
    "    os.system(cmd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    eas_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/CAS/\"\n",
    "    eur_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/\"\n",
    "    eas_geno_base_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/CAS/geno/CAS_final/CAS_merged_qc_final\"\n",
    "    eur_geno_base_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/geno/White_British/0_sample_qc/\"\n",
    "    valid_output_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/prosper/valid/\"\n",
    "    tuning_output_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/prosper/tuning/\"\n",
    "    snp_list_path = \"/data1/jiapl_group/lishuhua/software/PRS/PROSPER/reference/snp_list.txt\"\n",
    "    plink_exec = \"/data1/jiapl_group/lishuhua/software/general/plink\"\n",
    "    TRAIT_LIST = ['waist', 'height', 'pulse', 'dbp', 'sbp', 'smoke', 'drink', 'bmi', 'wbc', 'rbc', 'hb', 'plt', 'lymph', 'mono', 'neut', 'eos', 'alt', 'ast', 'bun', 'cholesterol', 'creatinine', 'glucose', 'ggt', 'hdl', 'ldl', 'triglycerides', 'ua']\n",
    "\n",
    "    for trait in TRAIT_LIST:\n",
    "        print(f\"Processing trait: {trait}\")\n",
    "        for i in range(1, 11):\n",
    "            print(f'  Processing group: {i}')\n",
    "            valid_eas_ids_path = os.path.join(eas_base_dir, trait, f\"group_{i}\", \"ids\", \"test_ids.txt\")\n",
    "            valid_eas_pheno_path = os.path.join(eas_base_dir, trait, f\"group_{i}\", \"pheno\", \"test_pheno.txt\")\n",
    "            tune_eas_ids_path = os.path.join(eas_base_dir, trait, f\"group_{i}\", \"ids\", \"tune_ids.txt\")\n",
    "            tune_eas_pheno_path = os.path.join(eas_base_dir, trait, f\"group_{i}\", \"pheno\", \"tune_pheno.txt\")\n",
    "            valid_output_path = os.path.join(valid_output_base_dir, \"EAS\", trait)\n",
    "            if not os.path.exists(valid_output_path):\n",
    "                os.makedirs(valid_output_path)\n",
    "            valid_output_prefix = os.path.join(valid_output_path, f\"group_{i}\")\n",
    "            tuning_output_path = os.path.join(tuning_output_base_dir, \"EAS\", trait)\n",
    "            if not os.path.exists(tuning_output_path):\n",
    "                os.makedirs(tuning_output_path)\n",
    "            tuning_output_prefix = os.path.join(tuning_output_path, f\"group_{i}\")\n",
    "            process_single_file(eas_geno_base_path, valid_eas_ids_path, valid_eas_pheno_path, snp_list_path, valid_output_prefix, plink_exec)\n",
    "            process_single_file(eas_geno_base_path, tune_eas_ids_path, tune_eas_pheno_path, snp_list_path, tuning_output_prefix, plink_exec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be62c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "eur_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/\"\n",
    "\n",
    "for i in range(1, 11):\n",
    "    print(f'Processing fold: {i}')\n",
    "\n",
    "    tune_pheno_path = os.path.join(eur_base_dir, \"pheno\", f\"fold_{i}\", \"tune_pheno_int.txt\")\n",
    "    tune_output_path = os.path.join(eur_base_dir, \"pheno\", f\"fold_{i}\", \"tune_pheno_int_cleaned.txt\")\n",
    "    test_pheno_path = os.path.join(eur_base_dir, \"pheno\", f\"fold_{i}\", \"test_pheno_int.txt\")\n",
    "    test_output_path = os.path.join(eur_base_dir, \"pheno\", f\"fold_{i}\", \"test_pheno_int_cleaned.txt\")\n",
    "\n",
    "    # clean the tune pheno file\n",
    "    tune_pheno_df = pd.read_csv(tune_pheno_path, sep=\"\\t\", header=0)\n",
    "    tune_pheno_df = tune_pheno_df.dropna(subset=tune_pheno_df.columns[2:])  # drop rows with NA in any trait column\n",
    "    tune_pheno_df.to_csv(tune_output_path, sep=\"\\t\", index=False)\n",
    "    # clean the test pheno file\n",
    "    test_pheno_df = pd.read_csv(test_pheno_path, sep=\"\\t\", header=0)\n",
    "    test_pheno_df = test_pheno_df.dropna(subset=test_pheno_df.columns[2:])  # drop rows with NA in any trait column\n",
    "    test_pheno_df.to_csv(test_output_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0fee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only get the fam file for each fold genotype data of EUR\n",
    "# /data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/pheno/fold_1/tune_pheno_int.txt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "trait_dict = {\n",
    "        'p48': 'waist',\n",
    "        'p50': 'height',\n",
    "        'p102': 'pulse',\n",
    "        'p4079': 'dbp',\n",
    "        'p4080': 'sbp',\n",
    "        'p20116': 'smoke',\n",
    "        'p20117': 'drink',\n",
    "        'p21001': 'bmi',\n",
    "        'p30000': 'wbc',\n",
    "        'p30010': 'rbc',\n",
    "        'p30020':'hb',\n",
    "        'p30080': 'plt',\n",
    "        'p30120': 'lymph',\n",
    "        'p30130': 'mono',\n",
    "        'p30140': 'neut',\n",
    "        'p30150': 'eos',\n",
    "        'p30620': 'alt',\n",
    "        'p30650': 'ast',\n",
    "        'p30670': 'bun',\n",
    "        'p30690': 'cholesterol',\n",
    "        'p30700': 'creatinine',\n",
    "        'p30730': 'ggt',\n",
    "        'p30740': 'glucose',\n",
    "        'p30760': 'hdl',\n",
    "        'p30780': 'ldl',\n",
    "        'p30870': 'triglycerides',\n",
    "        'p30880': 'ua'\n",
    "    }\n",
    "\n",
    "def extract_fam(bfile_path, pheno_path, pheno_name, output_path, plink_exec):\n",
    "    cmd = f\"{plink_exec} --bfile {bfile_path} --pheno {pheno_path} --pheno-name {pheno_name} --make-just-fam --out {output_path}\"\n",
    "    os.system(cmd)\n",
    "\n",
    "# /data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/tune/fold_1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    eur_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/Cross_Validation/UKB_EUR/\"\n",
    "    output_base_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/software/prosper/\"\n",
    "    plink_exec = \"/data1/jiapl_group/lishuhua/software/general/plink\"\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        print(f'Processing fold: {i}')\n",
    "        # process tune and test data\n",
    "        tune_pheno_path = os.path.join(eur_base_dir, \"pheno\", f\"fold_{i}\", \"tune_pheno_int_cleaned.txt\")\n",
    "        test_pheno_path = os.path.join(eur_base_dir, \"pheno\", f\"fold_{i}\", \"test_pheno_int_cleaned.txt\")\n",
    "        tune_bfile_base_path = os.path.join(eur_base_dir, \"tune\", f\"fold_{i}\", \"chr\")\n",
    "        test_bfile_base_path = os.path.join(eur_base_dir, \"test\", f\"fold_{i}\", \"chr\")\n",
    "\n",
    "        for chrom in range(1, 23):\n",
    "            print(f'  Processing chromosome: {chrom}')\n",
    "            tune_bfile_path = f\"{tune_bfile_base_path}{chrom}\"\n",
    "            test_bfile_path = f\"{test_bfile_base_path}{chrom}\"\n",
    "            for trait_id, trait in trait_dict.items():\n",
    "                print(f'    Processing trait: {trait} ({trait_id})')\n",
    "                tune_output_path = os.path.join(output_base_dir, \"tuning\", \"EUR\", trait, f\"group_{i}_chr{chrom}\")\n",
    "                test_output_path = os.path.join(output_base_dir, \"valid\", \"EUR\", trait, f\"group_{i}_chr{chrom}\")\n",
    "                if not os.path.exists(os.path.join(output_base_dir, \"tuning\", \"EUR\", trait)):\n",
    "                    os.makedirs(os.path.join(output_base_dir, \"tuning\", \"EUR\", trait))\n",
    "                if not os.path.exists(os.path.join(output_base_dir, \"valid\", \"EUR\", trait)):\n",
    "                    os.makedirs(os.path.join(output_base_dir, \"valid\", \"EUR\", trait))\n",
    "                if not os.path.exists(tune_output_path + \".fam\"):\n",
    "                    extract_fam(tune_bfile_path, tune_pheno_path, trait_id+\"_int\", tune_output_path, plink_exec)\n",
    "                else:\n",
    "                    print(f\"  {tune_output_path}.fam already exists, skipping...\")\n",
    "                if not os.path.exists(test_output_path + \".fam\"):\n",
    "                    extract_fam(test_bfile_path, test_pheno_path, trait_id+\"_int\", test_output_path, plink_exec)\n",
    "                else:\n",
    "                    print(f\"  {test_output_path}.fam already exists, skipping...\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
