{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7fc257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! test demo !!!\n",
    "# ldsc: /data1/jiapl_group/lishuhua/software/general/ldsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b077b4",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# caculate LD score for UK Biobank data (no so much memory, give up)\n",
    "for i in {1..22}\n",
    "do\n",
    "    echo \"--- Calculating LD score for chr${i} ---\"\n",
    "    python /data1/jiapl_group/lishuhua/software/general/ldsc/ldsc.py \\\n",
    "        --l2 \\\n",
    "        --bfile /data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/geno/White_British/0_sample_qc/chr${i} \\\n",
    "        --ld-wind-cm 1 \\\n",
    "        --out /data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/UKB_baselineLD/ldscore_chr${i}\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b9ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: convert .glm files to .sumstats files\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "from multiprocessing import Pool, cpu_count\n",
    "# Define paths\n",
    "munge_script = \"/data1/jiapl_group/lishuhua/software/general/ldsc/munge_sumstats.py\"\n",
    "merge_allele_file_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/snpinfo_mult_1kg_hm3\"\n",
    "gwas_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/White_British/gwas/\"\n",
    "temp_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/White_British/temp/\"\n",
    "munged_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/White_British/munged/\"\n",
    "\n",
    "def convert_gwas_to_sumstats(gwas_file, out_file):\n",
    "    df = pd.read_csv(gwas_file, sep=\"\\t\", header=0, low_memory=False)\n",
    "    print df.head()\n",
    "    # check if the BETA column is present\n",
    "    if \"BETA\" not in df.columns:\n",
    "        required_columns = [\"ID\", \"ALT\", \"REF\", \"OR\", \"LOG(OR)_SE\", \"P\", \"OBS_CT\"]\n",
    "    else:\n",
    "        required_columns = [\"ID\", \"ALT\", \"REF\", \"BETA\", \"SE\", \"P\", \"OBS_CT\"]\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(\"GWAS file %s does not contain all required columns: %s\" % (gwas_file, required_columns))\n",
    "\n",
    "    df = df[required_columns]\n",
    "    if \"LOG(OR)_SE\" in df.columns:\n",
    "        df.rename(columns={\"LOG(OR)_SE\": \"SE\"}, inplace=True)\n",
    "    df.rename(columns={\"ID\": \"SNP\", \"ALT\": \"A2\", \"REF\": \"A1\", \"OBS_CT\": \"N\"}, inplace=True)\n",
    "    df[\"N\"] = df[\"N\"].astype(int)\n",
    "    df[\"P\"] = df[\"P\"].astype(float)\n",
    "    if \"OR\" in df.columns:\n",
    "        df[\"OR\"] = df[\"OR\"].astype(float)\n",
    "    elif \"BETA\" in df.columns:\n",
    "        df[\"BETA\"] = df[\"BETA\"].astype(float)\n",
    "    else:\n",
    "        raise ValueError(\"GWAS file %s does not contain OR or BETA column.\" % gwas_file)\n",
    "    df[\"SE\"] = df[\"SE\"].astype(float)\n",
    "    df[\"A1\"] = df[\"A1\"].astype(str)\n",
    "    df[\"A2\"] = df[\"A2\"].astype(str)\n",
    "    df.to_csv(out_file, sep=\"\\t\", index=False, header=True)\n",
    "\n",
    "def process_single(args):\n",
    "    gwas_file, temp_file, out_file, munge_script, merge_allele_file_path = args\n",
    "    # Convert GWAS file to sumstats format\n",
    "    convert_gwas_to_sumstats(gwas_file, temp_file)\n",
    "\n",
    "    # Run the munge script\n",
    "    cmd = [\n",
    "        \"python\", munge_script,\n",
    "        \"--sumstats\", temp_file,\n",
    "        \"--merge-alleles\", merge_allele_file_path,\n",
    "        \"--out\", out_file.replace(\"_sumstats.txt\", \"\")\n",
    "    ]\n",
    "    subprocess.call(cmd)\n",
    "    return \"Processed %s to %s\" % (gwas_file, out_file)\n",
    "\n",
    "def batch_convert_gwas_to_sumstats(gwas_dir, munged_dir, temp_dir, munge_script, merge_allele_file_path, num_threads=None):\n",
    "    if not os.path.exists(munged_dir):\n",
    "        os.makedirs(munged_dir)\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "\n",
    "    tasks = []\n",
    "    for fname in os.listdir(gwas_dir):\n",
    "        if fname.endswith(\".glm.linear\"):\n",
    "            name = fname.replace(\".glm.linear\", \"\")\n",
    "            gwas_file = os.path.join(gwas_dir, fname)\n",
    "            temp_file = os.path.join(temp_dir, \"%s_clean.txt\" % name)\n",
    "            out_file = os.path.join(munged_dir, \"%s_sumstats.txt\" % name)\n",
    "            print \"Converting GWAS file %s to sumstats format.\" % gwas_file\n",
    "            tasks.append((gwas_file, temp_file, out_file, munge_script, merge_allele_file_path))\n",
    "        if fname.endswith(\".glm.logistic\"):\n",
    "            name = fname.replace(\".glm.logistic\", \"\")\n",
    "            gwas_file = os.path.join(gwas_dir, fname)\n",
    "            temp_file = os.path.join(temp_dir, \"%s_clean.txt\" % name)\n",
    "            out_file = os.path.join(munged_dir, \"%s_sumstats.txt\" % name)\n",
    "            print \"Converting GWAS file %s to sumstats format.\" % gwas_file\n",
    "            tasks.append((gwas_file, temp_file, out_file, munge_script, merge_allele_file_path))\n",
    "    \n",
    "    pool = Pool(processes=num_threads or cpu_count())\n",
    "    results = pool.map(process_single, tasks)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n",
    "# Convert GWAS results to sumstats format for EUR and EAS populations\n",
    "batch_convert_gwas_to_sumstats(gwas_path, munged_dir, temp_dir, munge_script, merge_allele_file_path, num_threads=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: convert .glm files to .sumstats files\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "from multiprocessing import Pool, cpu_count\n",
    "# Define paths\n",
    "munge_script = \"/data1/jiapl_group/lishuhua/software/general/ldsc/munge_sumstats.py\"\n",
    "merge_allele_file_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/snpinfo_mult_1kg_hm3\"\n",
    "gwas_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/Chinese/gwas/\"\n",
    "temp_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/Chinese/temp/\"\n",
    "munged_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/Chinese/munged/\"\n",
    "\n",
    "def convert_gwas_to_sumstats(gwas_file, out_file):\n",
    "    df = pd.read_csv(gwas_file, sep=\"\\t\", header=0, low_memory=False)\n",
    "    print df.head()\n",
    "    # check if the BETA column is present\n",
    "    if \"BETA\" not in df.columns:\n",
    "        required_columns = [\"ID\", \"ALT\", \"REF\", \"OR\", \"LOG(OR)_SE\", \"P\", \"OBS_CT\"]\n",
    "    else:\n",
    "        required_columns = [\"ID\", \"ALT\", \"REF\", \"BETA\", \"SE\", \"P\", \"OBS_CT\"]\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(\"GWAS file %s does not contain all required columns: %s\" % (gwas_file, required_columns))\n",
    "\n",
    "    df = df[required_columns]\n",
    "    if \"LOG(OR)_SE\" in df.columns:\n",
    "        df.rename(columns={\"LOG(OR)_SE\": \"SE\"}, inplace=True)\n",
    "    df.rename(columns={\"ID\": \"SNP\", \"ALT\": \"A2\", \"REF\": \"A1\", \"OBS_CT\": \"N\"}, inplace=True)\n",
    "    df[\"N\"] = df[\"N\"].astype(int)\n",
    "    df[\"P\"] = df[\"P\"].astype(float)\n",
    "    if \"OR\" in df.columns:\n",
    "        df[\"OR\"] = df[\"OR\"].astype(float)\n",
    "    elif \"BETA\" in df.columns:\n",
    "        df[\"BETA\"] = df[\"BETA\"].astype(float)\n",
    "    else:\n",
    "        raise ValueError(\"GWAS file %s does not contain OR or BETA column.\" % gwas_file)\n",
    "    df[\"SE\"] = df[\"SE\"].astype(float)\n",
    "    df[\"A1\"] = df[\"A1\"].astype(str)\n",
    "    df[\"A2\"] = df[\"A2\"].astype(str)\n",
    "    df.to_csv(out_file, sep=\"\\t\", index=False, header=True)\n",
    "\n",
    "def process_single(args):\n",
    "    gwas_file, temp_file, out_file, munge_script, merge_allele_file_path = args\n",
    "    # Convert GWAS file to sumstats format\n",
    "    convert_gwas_to_sumstats(gwas_file, temp_file)\n",
    "\n",
    "    # Run the munge script\n",
    "    cmd = [\n",
    "        \"python\", munge_script,\n",
    "        \"--sumstats\", temp_file,\n",
    "        \"--merge-alleles\", merge_allele_file_path,\n",
    "        \"--out\", out_file.replace(\"_sumstats.txt\", \"\")\n",
    "    ]\n",
    "    subprocess.call(cmd)\n",
    "    return \"Processed %s to %s\" % (gwas_file, out_file)\n",
    "\n",
    "def batch_convert_gwas_to_sumstats(gwas_dir, munged_dir, temp_dir, munge_script, merge_allele_file_path, num_threads=None):\n",
    "    if not os.path.exists(munged_dir):\n",
    "        os.makedirs(munged_dir)\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "\n",
    "    tasks = []\n",
    "    for fname in os.listdir(gwas_dir):\n",
    "        if fname.endswith(\".glm.linear\"):\n",
    "            name = fname.replace(\".glm.linear\", \"\")\n",
    "            gwas_file = os.path.join(gwas_dir, fname)\n",
    "            temp_file = os.path.join(temp_dir, \"%s_clean.txt\" % name)\n",
    "            out_file = os.path.join(munged_dir, \"%s_sumstats.txt\" % name)\n",
    "            print \"Converting GWAS file %s to sumstats format.\" % gwas_file\n",
    "            tasks.append((gwas_file, temp_file, out_file, munge_script, merge_allele_file_path))\n",
    "        if fname.endswith(\".glm.logistic\"):\n",
    "            name = fname.replace(\".glm.logistic\", \"\")\n",
    "            gwas_file = os.path.join(gwas_dir, fname)\n",
    "            temp_file = os.path.join(temp_dir, \"%s_clean.txt\" % name)\n",
    "            out_file = os.path.join(munged_dir, \"%s_sumstats.txt\" % name)\n",
    "            print \"Converting GWAS file %s to sumstats format.\" % gwas_file\n",
    "            tasks.append((gwas_file, temp_file, out_file, munge_script, merge_allele_file_path))\n",
    "    \n",
    "    pool = Pool(processes=num_threads or cpu_count())\n",
    "    results = pool.map(process_single, tasks)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n",
    "# Convert GWAS results to sumstats format for EUR and EAS populations\n",
    "batch_convert_gwas_to_sumstats(gwas_path, munged_dir, temp_dir, munge_script, merge_allele_file_path, num_threads=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c819411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caculate r2 for each trait in CAS cohort\n",
    "import subprocess\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "eur_munged_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/White_British/munged/\"\n",
    "eas_munged_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/CAS/gwas/munged/\"\n",
    "eur_ld_ref_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/EUR_baselineLD/baselineLD.\"\n",
    "eur_w_ld_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/EUR_ldscores/LDscore.\"\n",
    "eas_ld_ref_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/EAS_baselineLD/baselineLD.\"\n",
    "eas_w_ld_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/EAS_ldscores/weights.EAS.hm3_noMHC.\"\n",
    "eur_output_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/White_British/h2/\"\n",
    "eas_output_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/CAS/gwas/h2/\"\n",
    "\n",
    "def run_ldsc(sumstats_file, ld_ref, weights_ref, out_prefix):\n",
    "    cmd = [\n",
    "        \"python\", \"/data1/jiapl_group/lishuhua/software/general/ldsc/ldsc.py\",\n",
    "        \"--h2\", sumstats_file,\n",
    "        \"--ref-ld-chr\", ld_ref,\n",
    "        \"--w-ld-chr\", weights_ref,\n",
    "        \"--out\", out_prefix,\n",
    "    ]\n",
    "    subprocess.call(cmd)\n",
    "\n",
    "# test command: python /p300s/jiapl_group/lishuhua/software/ldsc/ldsc.py --h2 /p300s/jiapl_group/lishuhua/PRS_benchmark/reference/shared_snp/simulated_gwas/munge_sumstats/EUR/sim_0.001_0.05_0.8_6.sumstats.gz --ref-ld-chr /p300s/jiapl_group/lishuhua/PRS_benchmark/software/ldsc/ldscore/eur_w_ld_hm3/LDscore/LDscore. --w-ld-chr /p300s/jiapl_group/lishuhua/PRS_benchmark/software/ldsc/ldscore/eur_w_ld_hm3/LDscore/LDscore. --out /p300s/jiapl_group/lishuhua/PRS_benchmark/reference/shared_snp/simulated_gwas/heritability/EUR/sim_0.001_0.05_0.8_6\n",
    "\n",
    "# run ldsc to estimate heritability for EUR and EAS populations\n",
    "def batch_run_ldsc(munged_dir, ld_ref, weights_ref, out_dir, num_threads=None):\n",
    "    # Create output directory if it doesn't exist\n",
    "    try:\n",
    "        os.makedirs(out_dir)\n",
    "    except OSError as e:\n",
    "        if e.errno != os.errno.EEXIST:  # If it already exists, ignore\n",
    "            raise\n",
    "    \n",
    "    tasks = []\n",
    "    for fname in os.listdir(munged_dir):\n",
    "        if fname.endswith(\".sumstats.gz\"):\n",
    "            sumstats_file = os.path.join(munged_dir, fname)\n",
    "            out_prefix = os.path.join(out_dir, fname.replace(\".sumstats.gz\", \"\"))\n",
    "            tasks.append((sumstats_file, ld_ref, weights_ref, out_prefix))\n",
    "    \n",
    "    pool = Pool(processes=num_threads or cpu_count())\n",
    "    # Use map instead of starmap\n",
    "    for task in tasks:\n",
    "        pool.apply_async(run_ldsc, task)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "# Run LDSC for EUR and EAS populations\n",
    "batch_run_ldsc(eur_munged_dir, eur_ld_ref_path, eur_w_ld_path, eur_output_path, num_threads=48)\n",
    "batch_run_ldsc(eas_munged_dir, eas_ld_ref_path, eas_w_ld_path, eas_output_path, num_threads=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd64e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caculate r2 for each trait in UKBB (EAS)\n",
    "import subprocess\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "eas_munged_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/Chinese/munged/\"\n",
    "eas_ld_ref_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/EAS_baselineLD/baselineLD.\"\n",
    "eas_w_ld_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/EAS_ldscores/weights.EAS.hm3_noMHC.\"\n",
    "eas_output_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/Chinese/h2/\"\n",
    "\n",
    "def run_ldsc(sumstats_file, ld_ref, weights_ref, out_prefix):\n",
    "    cmd = [\n",
    "        \"python\", \"/data1/jiapl_group/lishuhua/software/general/ldsc/ldsc.py\",\n",
    "        \"--h2\", sumstats_file,\n",
    "        \"--ref-ld-chr\", ld_ref,\n",
    "        \"--w-ld-chr\", weights_ref,\n",
    "        \"--out\", out_prefix,\n",
    "    ]\n",
    "    subprocess.call(cmd)\n",
    "\n",
    "# test command: python /p300s/jiapl_group/lishuhua/software/ldsc/ldsc.py --h2 /p300s/jiapl_group/lishuhua/PRS_benchmark/reference/shared_snp/simulated_gwas/munge_sumstats/EUR/sim_0.001_0.05_0.8_6.sumstats.gz --ref-ld-chr /p300s/jiapl_group/lishuhua/PRS_benchmark/software/ldsc/ldscore/eur_w_ld_hm3/LDscore/LDscore. --w-ld-chr /p300s/jiapl_group/lishuhua/PRS_benchmark/software/ldsc/ldscore/eur_w_ld_hm3/LDscore/LDscore. --out /p300s/jiapl_group/lishuhua/PRS_benchmark/reference/shared_snp/simulated_gwas/heritability/EUR/sim_0.001_0.05_0.8_6\n",
    "\n",
    "# run ldsc to estimate heritability for EUR and EAS populations\n",
    "def batch_run_ldsc(munged_dir, ld_ref, weights_ref, out_dir, num_threads=None):\n",
    "    # Create output directory if it doesn't exist\n",
    "    try:\n",
    "        os.makedirs(out_dir)\n",
    "    except OSError as e:\n",
    "        if e.errno != os.errno.EEXIST:  # If it already exists, ignore\n",
    "            raise\n",
    "    \n",
    "    tasks = []\n",
    "    for fname in os.listdir(munged_dir):\n",
    "        if fname.endswith(\".sumstats.gz\"):\n",
    "            sumstats_file = os.path.join(munged_dir, fname)\n",
    "            out_prefix = os.path.join(out_dir, fname.replace(\".sumstats.gz\", \"\"))\n",
    "            tasks.append((sumstats_file, ld_ref, weights_ref, out_prefix))\n",
    "    \n",
    "    pool = Pool(processes=num_threads or cpu_count())\n",
    "    # Use map instead of starmap\n",
    "    for task in tasks:\n",
    "        pool.apply_async(run_ldsc, task)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "# Run LDSC for EUR and EAS populations\n",
    "batch_run_ldsc(eas_munged_dir, eas_ld_ref_path, eas_w_ld_path, eas_output_path, num_threads=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a3d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caculate r2 for each trait in CAS cohort\n",
    "import subprocess\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# eur_munged_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/White_British/munged/\"\n",
    "# eas_munged_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/CAS/gwas/munged/\"\n",
    "eas_munged_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/Chinese/munged/\"\n",
    "# eur_ld_ref_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/EUR_baselineLD/baselineLD.\"\n",
    "# eur_w_ld_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/EUR_ldscores/LDscore.\"\n",
    "eas_ld_ref_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/EAS_baselineLD/baselineLD.\"\n",
    "eas_w_ld_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/EAS_ldscores/weights.EAS.hm3_noMHC.\"\n",
    "# eur_output_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/White_British/h2/\"\n",
    "# eas_output_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/CAS/gwas/corr/\"\n",
    "eas_output_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/Chinese/corr/\"\n",
    "\n",
    "def run_ldsc(sumstats_file, ld_ref, weights_ref, out_prefix):\n",
    "    cmd = [\n",
    "        \"python\", \"/data1/jiapl_group/lishuhua/software/general/ldsc/ldsc.py\",\n",
    "        \"--rg\", sumstats_file,\n",
    "        \"--ref-ld-chr\", ld_ref,\n",
    "        \"--w-ld-chr\", weights_ref,\n",
    "        \"--out\", out_prefix,\n",
    "    ]\n",
    "    subprocess.call(cmd)\n",
    "\n",
    "trait_dict = {\n",
    "        'p48': 'waist',\n",
    "        'p50': 'height',\n",
    "        'p102': 'pulse',\n",
    "        'p4079': 'dbp',\n",
    "        'p4080': 'sbp',\n",
    "        'p20116': 'smoke',\n",
    "        'p20117': 'drink',\n",
    "        'p21001': 'bmi',\n",
    "        'p30000': 'wbc',\n",
    "        'p30010': 'rbc',\n",
    "        'p30020':'hb',\n",
    "        'p30080': 'plt',\n",
    "        'p30120': 'lymph',\n",
    "        'p30130': 'mono',\n",
    "        'p30140': 'neut',\n",
    "        'p30150': 'eos',\n",
    "        'p30620': 'alt',\n",
    "        'p30650': 'ast',\n",
    "        'p30670': 'bun',\n",
    "        'p30690': 'cholesterol',\n",
    "        'p30700': 'creatinine',\n",
    "        'p30730': 'ggt',\n",
    "        'p30740': 'glucose',\n",
    "        'p30760': 'hdl',\n",
    "        'p30780': 'ldl',\n",
    "        'p30870': 'triglycerides',\n",
    "        'p30880': 'ua'\n",
    "    }\n",
    "for trait, trait_name in trait_dict.items():\n",
    "    for other_trait, other_trait_name in trait_dict.items():\n",
    "        # print(f\"Comparing {trait_name} with {other_trait_name}\")\n",
    "        if trait == other_trait:\n",
    "            continue\n",
    "        # alt_int.alt_int.sumstats.gz\n",
    "        # p20116_int.merged.sumstats.gz\n",
    "        # eas_sums_1 = os.path.join(eas_munged_dir, f\"{trait_name}_int.{trait_name}_int.sumstats.txt.gz\")\n",
    "        # eas_sums_2 = os.path.join(eas_munged_dir, f\"{other_trait_name}_int.{other_trait_name}_int.sumstats.txt.gz\")\n",
    "        eas_sums_1 = os.path.join(eas_munged_dir, f\"{trait}_int.merged.sumstats.txt.gz\")\n",
    "        eas_sums_2 = os.path.join(eas_munged_dir, f\"{other_trait}_int.merged.sumstats.txt.gz\")\n",
    "        eas_sum_path = f'{eas_sums_1},{eas_sums_2}'\n",
    "        eas_out_prefix = os.path.join(eas_output_path, f\"{trait_name}_{other_trait_name}_corr\")\n",
    "        run_ldsc(eas_sum_path, eas_ld_ref_path, eas_w_ld_path, eas_out_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc11dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# caculate r2 for each trait in CAS cohort\n",
    "import subprocess\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# eur_munged_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/White_British/munged/\"\n",
    "# eas_munged_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/CAS/gwas/munged/\"\n",
    "eas_munged_dir = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/Chinese/munged/\"\n",
    "# eur_ld_ref_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/EUR_baselineLD/baselineLD.\"\n",
    "# eur_w_ld_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/EUR_ldscores/LDscore.\"\n",
    "eas_ld_ref_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/EAS_baselineLD/baselineLD.\"\n",
    "eas_w_ld_path = \"/data1/jiapl_group/lishuhua/software/general/ldsc/LD_SCORE/EAS_ldscores/weights.EAS.hm3_noMHC.\"\n",
    "# eur_output_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/White_British/h2/\"\n",
    "# eas_output_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/CAS/gwas/corr/\"\n",
    "eas_output_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/merged_gwas/Chinese/corr/\"\n",
    "\n",
    "def run_ldsc(sumstats_file, ld_ref, weights_ref, out_prefix):\n",
    "    \"\"\"\n",
    "    运行 ldsc 命令的函数\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        \"python\", \"/data1/jiapl_group/lishuhua/software/general/ldsc/ldsc.py\",\n",
    "        \"--rg\", sumstats_file,\n",
    "        \"--ref-ld-chr\", ld_ref,\n",
    "        \"--w-ld-chr\", weights_ref,\n",
    "        \"--out\", out_prefix,\n",
    "    ]\n",
    "    subprocess.call(cmd)\n",
    "\n",
    "trait_dict = {\n",
    "        'p48': 'waist',\n",
    "        'p50': 'height',\n",
    "        'p102': 'pulse',\n",
    "        'p4079': 'dbp',\n",
    "        'p4080': 'sbp',\n",
    "        'p20116': 'smoke',\n",
    "        'p20117': 'drink',\n",
    "        'p21001': 'bmi',\n",
    "        'p30000': 'wbc',\n",
    "        'p30010': 'rbc',\n",
    "        'p30020':'hb',\n",
    "        'p30080': 'plt',\n",
    "        'p30120': 'lymph',\n",
    "        'p30130': 'mono',\n",
    "        'p30140': 'neut',\n",
    "        'p30150': 'eos',\n",
    "        'p30620': 'alt',\n",
    "        'p30650': 'ast',\n",
    "        'p30670': 'bun',\n",
    "        'p30690': 'cholesterol',\n",
    "        'p30700': 'creatinine',\n",
    "        'p30730': 'ggt',\n",
    "        'p30740': 'glucose',\n",
    "        'p30760': 'hdl',\n",
    "        'p30780': 'ldl',\n",
    "        'p30870': 'triglycerides',\n",
    "        'p30880': 'ua'\n",
    "    }\n",
    "\n",
    "# 使用 .iteritems() 在 Python 2 中更高效\n",
    "for trait, trait_name in trait_dict.iteritems():\n",
    "    for other_trait, other_trait_name in trait_dict.iteritems():\n",
    "        # print \"Comparing {} with {}\".format(trait_name, other_trait_name)\n",
    "        if trait == other_trait:\n",
    "            continue\n",
    "        \n",
    "        # 将 f-string 替换为 .format() 方法\n",
    "        eas_sums_1 = os.path.join(eas_munged_dir, \"{}_int.merged.sumstats.gz\".format(trait))\n",
    "        eas_sums_2 = os.path.join(eas_munged_dir, \"{}_int.merged.sumstats.gz\".format(other_trait))\n",
    "        \n",
    "        eas_sum_path = '{},{}'.format(eas_sums_1, eas_sums_2)\n",
    "        \n",
    "        eas_out_prefix = os.path.join(eas_output_path, \"{}_{}_corr\".format(trait_name, other_trait_name))\n",
    "        if os.path.exists(eas_out_prefix + \".log\"):\n",
    "            print(\"File {} already exists, skipping...\".format(eas_out_prefix + \".log\"))\n",
    "            continue\n",
    "        \n",
    "        run_ldsc(eas_sum_path, eas_ld_ref_path, eas_w_ld_path, eas_out_prefix)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
