{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c54d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data_path_list = [\n",
    "    \"/data1/jiapl_group/lishuhua/UKB/Phenotype/fields/core_category/fields_group_34.tsv\",\n",
    "    \"/data1/jiapl_group/lishuhua/UKB/Phenotype/fields/third_category/third_group_27.tsv\",\n",
    "    \"/data1/jiapl_group/lishuhua/UKB/Phenotype/fields/third_category/third_group_30.tsv\"\n",
    "]\n",
    "\n",
    "field_ids = [\"p41202\", \"p41203\", \"p41204\", \"p41205\", \"p41270\", \"p41271\", \"p\"]\n",
    "\n",
    "data_frames = []\n",
    "for file_path in data_path_list:\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File {file_path} does not exist.\")\n",
    "        continue\n",
    "    columns = pd.read_csv(file_path, sep='\\t', nrows=0).columns.tolist()\n",
    "    overlap_columns = set(columns).intersection(field_ids)\n",
    "    if not overlap_columns:\n",
    "        print(f\"No overlapping columns found in {file_path}.\")\n",
    "        continue\n",
    "    df = pd.read_csv(file_path, sep='\\t', usecols=['eid'] + list(overlap_columns), header=0, na_values=['NA', '.', '-9', ''])\n",
    "    data_frames.append(df)\n",
    "\n",
    "if data_frames:\n",
    "    merge_df = data_frames[0]\n",
    "    for df in data_frames[1:]:\n",
    "        merge_df = pd.merge(merge_df, df, on='eid', how='outer')\n",
    "    \n",
    "    output_file = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB_ICD/pheno/icd_pheno.tsv\"\n",
    "    merge_df.to_csv(output_file, sep='\\t', index=False, header=True, na_rep='')\n",
    "    print(f\"Data merged successfully and saved to {output_file}.\")\n",
    "else:\n",
    "    print(\"No data frames to merge. Please check the input files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd68c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7_merge_ukb_pheno.py\n",
    "\n",
    "# merge all instances and arrays into a single column\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm, rankdata\n",
    "import os\n",
    "import re\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "def inverse_normal_transform(x):\n",
    "    \"\"\"Perform inverse normal transformation on a series.\"\"\"\n",
    "    values = np.array(x)\n",
    "    is_na = np.isnan(values)\n",
    "    ranks = rankdata(values[~is_na], method='average')\n",
    "    transformed = np.empty_like(values, dtype=float)\n",
    "    transformed[~is_na] = norm.ppf( (ranks - 0.5) / len(ranks) )\n",
    "    transformed[is_na] = np.nan  # Keep NaNs in the same places\n",
    "    # Ensure the transformed values are calulated correctly\n",
    "    transformed = pd.Series(transformed, index=x.index)\n",
    "    # transformed = transformed.astype(float)  # Ensure the type is float\n",
    "    return transformed\n",
    "\n",
    "def change_category_to_binary(x):\n",
    "    \"\"\"Convert a series to binary (0/1) if it contains only two unique values.\"\"\"\n",
    "    # change all -3 as NaN\n",
    "    x = x.replace(-3, np.nan)\n",
    "    # Only proceed if there are exactly two unique non-NaN values\n",
    "    unique_vals = pd.Series(x).dropna().unique()\n",
    "    if len(unique_vals) == 3:\n",
    "        # Map the smaller value to 0, the larger to 1\n",
    "        sorted_vals = sorted(unique_vals)\n",
    "        mapping = {sorted_vals[0]: 1, sorted_vals[1]: 1, sorted_vals[2]: 2}\n",
    "        x = x.map(mapping)\n",
    "    transformed = pd.Series(x, index=x.index)\n",
    "    return transformed\n",
    "\n",
    "def is_categorical(series, max_n_unique=20, min_n_unique=2):\n",
    "    \"\"\"Check if a series is categorical based on the number of unique values.\"\"\"\n",
    "    series = series.dropna()\n",
    "    unique_vals = set(series.unique())\n",
    "\n",
    "    if series.dtype.kind not in 'iui' and not all( (float(x).is_integer() for x in unique_vals) ):\n",
    "        return False\n",
    "    n_unique = len(unique_vals)\n",
    "    if 1 < n_unique <= max_n_unique and not unique_vals.issubset({0, 1}):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def process_one_phenotype(df, pheno_prefix, output_dir='/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB_ICD/pheno/'):\n",
    "    pattern = re.compile(rf\"^{pheno_prefix}_i\\d+(_a\\d+)?$\")\n",
    "    cols = [col for col in df.columns if pattern.match(col)]\n",
    "\n",
    "    if not cols:\n",
    "        print(f\"No columns found for prefix {pheno_prefix}.\")\n",
    "        return None\n",
    "    print(f\"[{pheno_prefix}] Processing columns: {cols}\")\n",
    "\n",
    "    pheno_raw = df[cols].bfill(axis=1).iloc[:, 0]\n",
    "\n",
    "    categorical = is_categorical(pheno_raw)\n",
    "\n",
    "    n_total = pheno_raw.shape[0]\n",
    "    n_no_missing = pheno_raw.notna().sum()\n",
    "\n",
    "    result = pd.DataFrame({\n",
    "        'eid': df['eid'],\n",
    "        f'{pheno_prefix}_raw': pheno_raw\n",
    "    })\n",
    "    \n",
    "    # figure_output_path = os.path.join(output_dir, f\"/distribution/\")\n",
    "    # os.makedirs(os.path.dirname(figure_output_path), exist_ok=True)\n",
    "\n",
    "    if categorical:\n",
    "        counts = pheno_raw.value_counts(dropna=True).to_dict()\n",
    "        pheno_int = change_category_to_binary(pheno_raw)\n",
    "        result[f'{pheno_prefix}_int'] = pheno_int\n",
    "        print(f\"[Categorical] Non-missing: {n_no_missing}, Category counts: {counts}\")\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.countplot(x=pheno_raw)\n",
    "        plt.title(f\"{pheno_prefix} Raw Distribution (Categorical)\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.countplot(x=pheno_int)\n",
    "        plt.title(f\"{pheno_prefix} Transform Distribution (Categorical)\")\n",
    "\n",
    "        plt.xlabel(\"Category\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/distribution/{pheno_prefix}_dist.png')\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(f\"[Continuous] Non-missing: {n_no_missing}, Mean: {pheno_raw.mean()}, Std: {pheno_raw.std()}\")\n",
    "        pheno_int = pd.Series(inverse_normal_transform(pheno_raw), index=pheno_raw.index)\n",
    "        result[f'{pheno_prefix}_int'] = pheno_int\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(pheno_raw, kde=True, bins=50, color='skyblue')\n",
    "        plt.title(f\"{pheno_prefix} Raw Distribution\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.histplot(pheno_int, kde=True, bins=50, color='salmon')\n",
    "        plt.title(f\"{pheno_prefix} Inverse Normal Distribution\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/distribution/{pheno_prefix}_dist.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def batch_process(df, pheno_prefixes, output_dir='/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB_ICD/pheno/'):\n",
    "    all_results = []\n",
    "    \n",
    "    for prefix in pheno_prefixes:\n",
    "        result = process_one_phenotype(df, prefix, output_dir)\n",
    "        if result is not None:\n",
    "            all_results.append(result)\n",
    "    if all_results:\n",
    "        all_merged = all_results[0]\n",
    "        for res in all_results[1:]:\n",
    "            all_merged = pd.merge(all_merged, res, on='eid', how='outer')\n",
    "        output_file = os.path.join(output_dir, 'icd_pheno_2.tsv')\n",
    "        all_merged.to_csv(output_file, sep='\\t', index=False, header=True, na_rep='')\n",
    "        print(f\"Processed data saved to {output_file}.\")\n",
    "    else:\n",
    "        print(\"No valid phenotypes processed. Please check the input data.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trait_path = '/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB_ICD/pheno/icd_pheno.tsv'\n",
    "    trait_df = pd.read_csv(trait_path, sep='\\t', na_values=['NA', '.', '-9', ''])\n",
    "    \n",
    "    pheno_prefixes = [\"p41202\", \"p41203\", \"p41204\", \"p41205\", \"p41270\", \"p41271\"]\n",
    "\n",
    "    batch_process(trait_df, pheno_prefixes)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
