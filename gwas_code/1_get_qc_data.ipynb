{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d4d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data_path_list = [\n",
    "    '/data1/jiapl_group/lishuhua/UKB/Phenotype/fields/core_category/fields_group_1.tsv',\n",
    "    '/data1/jiapl_group/lishuhua/UKB/Phenotype/fields/core_category/fields_group_39.tsv',\n",
    "    '/data1/jiapl_group/lishuhua/UKB/Phenotype/fields/third_category/third_group_5.tsv',\n",
    "    '/data1/jiapl_group/lishuhua/UKB/Phenotype/fields/third_category/third_group_6.tsv'\n",
    "    ]\n",
    "fields_ids = ['p31', 'p21022', 'p22001', 'p22006', 'p22019', 'p22020', 'p22021', 'p22027', 'p22009_a1', 'p22009_a2', 'p22009_a3', 'p22009_a4', 'p22009_a5', 'p22009_a6', 'p22009_a7', 'p22009_a8', 'p22009_a9', 'p22009_a10', 'p22009_a11', 'p22009_a12', 'p22009_a13', 'p22009_a14', 'p22009_a15', 'p22009_a16', 'p22009_a17', 'p22009_a18', 'p22009_a19', 'p22009_a20']\n",
    "\n",
    "# for each file, read the data and extract the relevant columns\n",
    "data_frames = []\n",
    "for file_path in data_path_list:\n",
    "    # search if the field_id column exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "    columns = pd.read_csv(file_path, sep='\\t', nrows=0).columns.tolist()\n",
    "    # find the overlap of columns with fields_ids\n",
    "    overlap_columns = set(columns).intersection(fields_ids)\n",
    "    if not overlap_columns:\n",
    "        print(f\"No relevant fields found in {file_path}\")\n",
    "        continue\n",
    "    # read the file and filter by fields_ids\n",
    "    df = pd.read_csv(file_path, sep='\\t', usecols=['eid'] + list(overlap_columns), header=0)\n",
    "    data_frames.append(df)\n",
    "\n",
    "# merge all data frames on 'eid'\n",
    "if data_frames:\n",
    "    merged_df = data_frames[0]\n",
    "    for df in data_frames[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on='eid', how='outer')\n",
    "    \n",
    "    # save the merged dataframe to a new file\n",
    "    output_file = '/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/pheno/covar/qc_covars.tsv'\n",
    "    merged_df.to_csv(output_file, sep='\\t', index=False, header=True)\n",
    "    print(f\"Merged data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fabd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample QC\n",
    "import pandas as pd\n",
    "\n",
    "qc_covars_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/pheno/covar/qc_covars.tsv\"\n",
    "# Load the QC covariates\n",
    "covars = pd.read_csv(qc_covars_path, sep='\\t')\n",
    "\n",
    "covars_qced = covars[(covars[\"p31\"] == covars[\"p22001\"]) & (covars[\"p22019\"].isnull()) & (covars[\"p22021\"] != 10) & (covars[\"p22027\"].isnull())]\n",
    "\n",
    "# Save the QCed covariates to a new file\n",
    "output_file_qced = '/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/pheno/covar/qc_covars_qced.tsv'\n",
    "covars_qced.to_csv(output_file_qced, sep='\\t', index=False, header=True)\n",
    "print(f\"QCed covariates saved to {output_file_qced}\")\n",
    "print(f\"Number of samples after QC: {len(covars_qced)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e49e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split qc_covars_qced into two cohorts: white British and Chinese\n",
    "import pandas as pd\n",
    "\n",
    "white_british_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/cohort/white_british_sample_ids.txt\"\n",
    "chinese_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/cohort/chinese_sample_ids.txt\"\n",
    "# Load the white British sample IDs\n",
    "white_british_ids = pd.read_csv(white_british_path, header=None, names=['FID', \"IID\"], sep='\\t')\n",
    "# Load the Chinese sample IDs\n",
    "chinese_ids = pd.read_csv(chinese_path, header=None, names=['FID', \"IID\"], sep='\\t')\n",
    "# Load the QC covariates\n",
    "qc_covars_qced_path = \"/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/pheno/covar/qc_covars_qced.tsv\"\n",
    "qc_covars_qced = pd.read_csv(qc_covars_qced_path, sep='\\t')\n",
    "qc_covars_qced[\"FID\"] = qc_covars_qced['eid']\n",
    "qc_covars_qced['IID'] = qc_covars_qced['eid']\n",
    "\n",
    "# Merge the white British IDs with the QC covariates\n",
    "merge_df_eur_qced = pd.merge(white_british_ids, qc_covars_qced, on=['FID','IID'], how='inner')\n",
    "merge_df_eur_qced = merge_df_eur_qced[(merge_df_eur_qced['p22006'] == 1) & (merge_df_eur_qced['p22020'] == 1)]  # filter for white British only\n",
    "# Merge the Chinese IDs with the QC covariates\n",
    "merge_df_eas_qced = pd.merge(chinese_ids, qc_covars_qced, on=['FID','IID'], how='inner')\n",
    "# check if there are full na rows (expect FID, IID, eid column) in the merged DataFrames\n",
    "check_eur = merge_df_eur_qced.drop(columns=['FID', 'IID', 'eid']).isnull().all(axis=1)\n",
    "check_eas = merge_df_eas_qced.drop(columns=['FID', 'IID', 'eid']).isnull().all(axis=1)\n",
    "if check_eur.any():\n",
    "    print(\"Warning: There are full NA rows in the merged white British DataFrame.\")\n",
    "if check_eas.any():\n",
    "    print(\"Warning: There are full NA rows in the merged Chinese DataFrame.\")\n",
    "# Save the merged DataFrame to a new file\n",
    "output_file_eur_qced = '/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/pheno/covar/covars_white_british_qced.tsv'\n",
    "output_file_eas_qced = '/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/pheno/covar/covars_chinese_qced.tsv'\n",
    "output_list_eur_qced = '/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/pheno/covar/covars_white_british_qced.txt'\n",
    "output_list_eas_qced = '/data1/jiapl_group/lishuhua/project/PRS_benchmark/real_data/UKB/pheno/covar/covars_chinese_qced.txt'\n",
    "merge_df_eur_qced.to_csv(output_file_eur_qced, sep='\\t', index=False, header=True)\n",
    "merge_df_eur_qced[['FID', 'IID']].to_csv(output_list_eur_qced, sep='\\t', index=False, header=False)\n",
    "print(f\"Merged data with white British sample IDs after QC saved to {output_file_eur_qced}\")\n",
    "print(f\"Number of samples in white British cohort after QC: {len(merge_df_eur_qced)}\")\n",
    "merge_df_eas_qced.to_csv(output_file_eas_qced, sep='\\t', index=False, header=True)\n",
    "merge_df_eas_qced[['FID', 'IID']].to_csv(output_list_eas_qced, sep='\\t', index=False, header=False)\n",
    "print(f\"Merged data with Chinese sample IDs after QC saved to {output_file_eas_qced}\")\n",
    "print(f\"Number of samples in Chinese cohort after QC: {len(merge_df_eas_qced)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
